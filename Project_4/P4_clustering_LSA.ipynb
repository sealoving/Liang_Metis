{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2467\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comments</th>\n",
       "      <th>description</th>\n",
       "      <th>duration</th>\n",
       "      <th>event</th>\n",
       "      <th>film_date</th>\n",
       "      <th>languages</th>\n",
       "      <th>main_speaker</th>\n",
       "      <th>name</th>\n",
       "      <th>num_speaker</th>\n",
       "      <th>published_date</th>\n",
       "      <th>ratings</th>\n",
       "      <th>related_talks</th>\n",
       "      <th>speaker_occupation</th>\n",
       "      <th>tags</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>views</th>\n",
       "      <th>transcript</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4553</td>\n",
       "      <td>Sir Ken Robinson makes an entertaining and pro...</td>\n",
       "      <td>1164</td>\n",
       "      <td>TED2006</td>\n",
       "      <td>1140825600</td>\n",
       "      <td>60</td>\n",
       "      <td>Ken Robinson</td>\n",
       "      <td>Ken Robinson: Do schools kill creativity?</td>\n",
       "      <td>1</td>\n",
       "      <td>1151367060</td>\n",
       "      <td>[{'id': 7, 'name': 'Funny', 'count': 19645}, {...</td>\n",
       "      <td>[{'id': 865, 'hero': 'https://pe.tedcdn.com/im...</td>\n",
       "      <td>Author/educator</td>\n",
       "      <td>['children', 'creativity', 'culture', 'dance',...</td>\n",
       "      <td>Do schools kill creativity?</td>\n",
       "      <td>https://www.ted.com/talks/ken_robinson_says_sc...</td>\n",
       "      <td>47227110</td>\n",
       "      <td>it been great hasnt it. ive been blown away by...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   comments                                        description  duration  \\\n",
       "0      4553  Sir Ken Robinson makes an entertaining and pro...      1164   \n",
       "\n",
       "     event   film_date  languages  main_speaker  \\\n",
       "0  TED2006  1140825600         60  Ken Robinson   \n",
       "\n",
       "                                        name  num_speaker  published_date  \\\n",
       "0  Ken Robinson: Do schools kill creativity?            1      1151367060   \n",
       "\n",
       "                                             ratings  \\\n",
       "0  [{'id': 7, 'name': 'Funny', 'count': 19645}, {...   \n",
       "\n",
       "                                       related_talks speaker_occupation  \\\n",
       "0  [{'id': 865, 'hero': 'https://pe.tedcdn.com/im...    Author/educator   \n",
       "\n",
       "                                                tags  \\\n",
       "0  ['children', 'creativity', 'culture', 'dance',...   \n",
       "\n",
       "                         title  \\\n",
       "0  Do schools kill creativity?   \n",
       "\n",
       "                                                 url     views  \\\n",
       "0  https://www.ted.com/talks/ken_robinson_says_sc...  47227110   \n",
       "\n",
       "                                          transcript  \n",
       "0  it been great hasnt it. ive been blown away by...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all = pd.read_pickle('./data/df_all_lemma.pkl')\n",
    "print(len(df_all))\n",
    "df_all.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['do', \"you're\", 'hadnt', 'd', 'o', 'out', 'be', 'y', \"you'll\", 'isn', 'same', 'most', \"mustn't\", 'he', 'down', \"didn't\", 'shes', 'th', \"isn't\", 'it', 'both', 'ain', 'aren', 'ours', \"you'd\", 'and', 'weren', 'just', 'through', 'dont', 'themselves', 'of', 'we', 'ha', 'other', 'yeah', 'yourselves', 'don', \"shouldn't\", 'mightn', 'ill', 'ma', 'because', 'whom', 'these', 'did', \"haven't\", 'its', 'isnt', 'again', 'about', 'off', \"don't\", 'mr', 'youd', 'your', 'has', 'does', \"she's\", 'wasnt', 'if', 'em', 'needn', 'him', 'when', 'arent', 'mrs', 'which', 'haven', 'shan', 'own', 'their', \"that'll\", 'under', 'further', 'theirs', 'hasn', 'yes', 'werent', 'youll', \"shan't\", 'won', 'didnt', 'she', 'doing', 'against', 'youve', 'shouldnt', 'that', 'before', 'them', 'hadn', 'more', 'his', 'wouldnt', 'they', 'between', 'you', 'ourselves', 'is', \"hasn't\", 'by', \"won't\", 'at', 'on', 'all', 're', 'doesn', 'mightnt', 'didn', 'shant', 'me', 'herself', 'myself', 'into', 'a', 'few', \"doesn't\", 'not', 'were', 'had', 'was', 'couldn', 'shouldn', 'with', 'wont', 'my', 'having', 'why', 's', 'only', 'from', 'hasnt', 'the', 'shouldve', 'there', 'have', 'how', 'mustn', 'during', 'too', 'ms', 'm', 'will', 'wouldn', 'our', \"you've\", \"mightn't\", 'are', 'over', 'to', \"wasn't\", 'then', 'any', \"aren't\", 'ca', 'i', 'been', 'while', \"hadn't\", 'hers', 'this', 'nor', 'no', \"should've\", 'havent', 'up', 'himself', 'what', 'as', 'here', 'now', 'neednt', 'yourself', 'once', 'where', 'those', 'but', 'an', 'above', \"it's\", \"couldn't\", 'oh', 'her', 'who', 'for', 'in', 'than', \"needn't\", 'ok', 't', 'wasn', 'okay', 'll', 'youre', 'yours', 'might', 'after', 'so', 'da', 'thatll', 've', 'am', 'can', 'ted', \"weren't\", 'should', 'each', 'some', 'such', 'below', \"wouldn't\", 'couldnt', 'being', 'until', 'mustnt', 'or', 'very', 'bg', 'doesnt', 'itself']\n"
     ]
    }
   ],
   "source": [
    "docs_all = list(df_all['transcript'])\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stops_standard = stopwords.words('english')\n",
    "stops_custom = ['shes','youll','ill','yeah','th','yes','oh',\n",
    "                'ok','okay','might','ha','mr','bg','ms',\n",
    "                'mrs','ca','em','da','ted']+[re.sub('[^A-Za-z ]+', '', w) for w in stops_standard]\n",
    "stop_list = list(set(stops_standard + stops_custom))\n",
    "\n",
    "print(stop_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting tf-idf features for LSA...\n",
      "done in 2.550s.\n",
      "Fitting LDA models with tf features, n_samples=2000 and n_features=2000...\n",
      "done in 0.180s.\n",
      "\n",
      "Topics in LSA model:\n",
      "Topic #0: music patient africa teacher cancer baby boy specie law india\n",
      "Topic #1: cancer robot patient dna universe ocean gene specie plant molecule\n",
      "Topic #2: cancer patient drug doctor tumor medical treatment hospital surgery medicine\n",
      "Topic #3: music robot song universe object artist playing musician film teacher\n",
      "Topic #4: robot economy device intelligence innovation leg network sensor mobile digital\n",
      "Topic #5: universe galaxy star telescope particle theory physic object quantum network\n",
      "Topic #6: music africa economy song growth musician china musical instrument innovation\n",
      "Topic #7: universe robot music dna africa gene galaxy cancer star violence\n",
      "Topic #8: dna gene genome specie virus plant bacteria genetic code molecule\n",
      "Topic #9: africa african baby teacher aid plant patient hiv dna sex\n",
      "Topic #10: cancer teacher tumor class india classroom robot english growth teach\n",
      "Topic #11: africa cancer african ocean film map continent camera aid fish\n",
      "Topic #12: ocean fish teacher coral sea shark reef classroom whale class\n",
      "Topic #13: dna virus teacher solar mar police drug nuclear boy prison\n",
      "Topic #14: teacher forest tree universe patient plant classroom class english teaching\n",
      "Topic #15: dna teacher genome india democracy architecture artist china structure gene\n",
      "Topic #16: india china chinese baby english indian song dna patient universe\n",
      "Topic #17: mar ice africa climate solar teacher compassion forest atmosphere cave\n",
      "Topic #18: neuron cancer fly forest tree map teacher violence network india\n",
      "Topic #19: film sex drug india plant movie teacher female male camera\n",
      "Topic #20: mar baby sex architecture neighborhood male site female cave boy\n",
      "Topic #21: compassion drug mar india religion religious indian prison painting artist\n",
      "Topic #22: forest drug tree film dna economy dance movie oil climate\n",
      "Topic #23: song fly plant neuron democracy bee election vote drug chinese\n",
      "Topic #24: film mar refugee universe specie movie gene worker innovation female\n",
      "Topic #25: sex oil map female sexual male boy gender gay africa\n",
      "Topic #26: device india object digital prison mobile forest boy physical movement\n",
      "Topic #27: compassion religion baby drug religious fly election film forest democracy\n",
      "Topic #28: song mar architecture prison baby film oil chinese law stem\n",
      "Topic #29: sex law rule male religion fly female dinosaur leg airplane\n",
      "Topic #30: song virus refugee vaccine climate architecture drug hiv sex structure\n",
      "Topic #31: song artist map plant climate bee dance network gene religion\n",
      "Topic #32: oil painting refugee dance song artist map network star teacher\n",
      "Topic #33: dance drug nuclear innovation india leader designer neuron leadership violence\n",
      "Topic #34: neuron india web poem poor pattern refugee prison dance page\n",
      "Topic #35: refugee drug climate ice dna web sex page photo cloud\n",
      "Topic #36: fly happiness english neuron designer tree flight forest gene airplane\n",
      "Topic #37: refugee dance map mar compassion camp prison chinese pattern happiness\n",
      "Topic #38: religion religious drug muslim dance gene english chinese poem character\n",
      "Topic #39: refugee english camp poem sex cloud nuclear oil film dance\n",
      "Topic #40: compassion english map violence gene mosquito specie nuclear film device\n",
      "Topic #41: happiness dance violence poem police photo page pm fly self\n",
      "Topic #42: paper bee self map happiness poem network letter nuclear tree\n",
      "Topic #43: plant gene happiness universe coral digital compassion architecture teacher painting\n",
      "Topic #44: dance mar web drug object pm architecture particle blind democracy\n",
      "Topic #45: dance dna ice teacher muslim neuron sex molecule film arab\n",
      "Topic #46: plastic memory photo nuclear waste happiness bacteria intelligence bottle election\n",
      "Topic #47: plastic neuron prison designer monkey hospital cloud dog molecule map\n",
      "Topic #48: object neuron map photo cloud trust plastic mar institution particle\n",
      "Topic #49: refugee happiness twitter song english bee india patient designer dinosaur\n",
      "\n"
     ]
    }
   ],
   "source": [
    "docs = docs_all\n",
    "\n",
    "from time import time\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation, TruncatedSVD\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "\n",
    "n_samples = 2000\n",
    "n_features = 2000\n",
    "n_components = 50\n",
    "n_top_words = 10\n",
    "n_gram = 1\n",
    "alpha = 0.1\n",
    "stop_choice= stop_list\n",
    "\n",
    "max_df = 400\n",
    "min_df = 10\n",
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        message = \"Topic #%d: \" % topic_idx\n",
    "        message += \" \".join([feature_names[i]\n",
    "                             for i in topic.argsort()[:-n_top_words - 1:-1]])\n",
    "        print(message)\n",
    "    print()\n",
    "\n",
    "\n",
    "# Use tf-idf features for LSA.\n",
    "print(\"Extracting tf-idf features for LSA...\")\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=max_df, min_df=min_df,\n",
    "                                   ngram_range=(n_gram,n_gram),\n",
    "                                   max_features=n_features,\n",
    "                                   stop_words=stop_choice)\n",
    "t0 = time()\n",
    "tfidf = tfidf_vectorizer.fit_transform(docs)\n",
    "print(\"done in %0.3fs.\" % (time() - t0))\n",
    "\n",
    "# Fit the LDA model\n",
    "print(\"Fitting LDA models with tf features, \"\n",
    "      \"n_samples=%d and n_features=%d...\"\n",
    "      % (n_samples, n_features))\n",
    "lsa = TruncatedSVD(n_components=n_components, algorithm = 'randomized',random_state=1)\n",
    "t0 = time()\n",
    "lsa.fit(tfidf)\n",
    "print(\"done in %0.3fs.\" % (time() - t0))\n",
    "\n",
    "print(\"\\nTopics in LSA model:\")\n",
    "tfidf_feature_names = tfidf_vectorizer.get_feature_names()\n",
    "print_top_words(lsa, tfidf_feature_names, n_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = lsa.fit_transform(tfidf)\n",
    "X = Normalizer(copy=False).fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[1999].argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find related talks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn.neighbors.kd_tree as kdtree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1999 \t Forget Wi-Fi. Meet the new Li-Fi Internet\n",
      "1105 \t A TED speaker's worst nightmare\n",
      "1873 \t How to land on a comet\n",
      "373 \t A solar energy system that tracks the sun\n",
      "1380 \t The mind behind Tesla, SpaceX, SolarCity ...\n",
      "2423 \t You owe it to yourself to experience a total solar eclipse\n",
      "2177 \t What a planet needs to sustain life\n",
      "2269 \t Why Earth may someday look like Mars\n",
      "2358 \t The future we're building -- and boring\n",
      "1194 \t Tour the solar system from home\n",
      "567 \t Fusion is energy's future\n",
      "145 \t This is Saturn\n",
      "1118 \t The missing link to renewable energy\n",
      "1644 \t The flower-shaped starshade that might help us detect Earth-like planets\n",
      "546 \t Learn to use the 13th-century astrolabe\n",
      "492 \t A demo of wireless electricity\n",
      "2258 \t Let's clean up the space junk orbiting Earth\n",
      "961 \t Finding planets around other stars\n",
      "1193 \t How to air-condition outdoor spaces\n",
      "2097 \t The most mysterious star in the universe\n"
     ]
    }
   ],
   "source": [
    "tree = kdtree.KDTree(X, leaf_size=10) \n",
    "N = 1999\n",
    "dist, ind = tree.query([X[N]], k=20)  \n",
    "for i in ind[0]:\n",
    "    print(i,'\\t',df_all.iloc[i].title)\n",
    "#     print(i,'\\t',df_all.iloc[i].views)\n",
    "#     print(df_all.iloc[i].tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Wireless data from every light bulb']\n",
      "['An Internet without screens might look like this']\n",
      "['Want to innovate? Become a \"now-ist\"']\n",
      "['A solar energy system that tracks the sun']\n",
      "['Caring for engineered tissue']\n",
      "['A light switch for neurons']\n"
     ]
    }
   ],
   "source": [
    "df_related = pd.DataFrame(eval(df_all.iloc[N]['related_talks']))\n",
    "for k in range(len(df_related)):\n",
    "    print(list(df_all[df_all['title']==df_related.iloc[k]['title']].title))\n",
    "#     print(df_all[df_all['title']==df_related.iloc[k]['title']].views)\n",
    "#     print(list(df_all[df_all['title']==df_related.iloc[k]['title']].tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# print(docs_all[395])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering using KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn import cluster\n",
    "\n",
    "n_clusters = 50\n",
    "\n",
    "# ward = cluster.AgglomerativeClustering(\n",
    "#     n_clusters=n_clusters, linkage='ward',\n",
    "#     connectivity=connectivity)\n",
    "spectral = cluster.SpectralClustering(\n",
    "    n_clusters=n_clusters, eigen_solver='arpack',\n",
    "    affinity=\"nearest_neighbors\")\n",
    "Xp = spectral.fit_predict(X)\n",
    "# dbscan = cluster.DBSCAN(eps=params['eps'])\n",
    "\n",
    "# km = KMeans(n_clusters=50)\n",
    "# Xt = km.fit_transform(X)\n",
    "\n",
    "# mu_docs = km.cluster_centers_\n",
    "# plt.plot(mu_docs.transpose())\n",
    "\n",
    "# silhouette_score(X, km.labels_, metric='euclidean')\n",
    "\n",
    "# sil_scores = []\n",
    "# iner_scores = []\n",
    "# ks = range(2,20)\n",
    "# for k in ks:\n",
    "#     km = KMeans(n_clusters=k)\n",
    "#     km.fit(X)\n",
    "#     sil_scores.append(silhouette_score(X, km.labels_, metric='euclidean'))\n",
    "#     iner_scores.append(km.inertia_)\n",
    "    \n",
    "# plt.plot(ks,sil_scores)\n",
    "# plt.plot(ks,iner_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([18, 29, 18, ..., 28, 18, 10], dtype=int32)"
      ]
     },
     "execution_count": 510,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1599 \t Love -- you're doing it wrong\n",
      "2343 \t 3 ways to plan for the (very) long term\n",
      "2085 \t How to get back to work after a career break\n",
      "1395 \t What makes us feel good about our work?\n",
      "1135 \t How I beat a patent troll\n",
      "1872 \t How equal do we want the world to be? You'd be surprised\n",
      "1821 \t The danger of hiding who you are\n",
      "1870 \t 5 ways to kill your dreams\n",
      "1566 \t The $80 prosthetic knee that's changing lives\n",
      "609 \t Plug into your hard-wired happiness\n"
     ]
    }
   ],
   "source": [
    "tree = kdtree.KDTree(Xt, leaf_size=10) \n",
    "# N = 1346\n",
    "dist, ind = tree.query([Xt[N]], k=10)  \n",
    "for i in ind[0]:\n",
    "    print(i,'\\t',df_all.iloc[i].title)\n",
    "#     print(i,'\\t',df_all.iloc[i].views)\n",
    "#     print(df_all.iloc[i].tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'and theyd say great. and ive been seeing that time horizon get shorter and shorter and shorter so much so that i met with a ceo two month ago and i said we started our initial conversation. he go i love what you do. i want to talk about the next six month. we have a lot of problem that we are facing. these are civilizationalscale problem. the issue though is we cant solve them using the mental model that we use right now to try and solve these problem. yes a lot of great technical work is being done but there is a problem that we need to solve for a priori before if we want to really move the needle on those big problem. shorttermism. right. there no march. there no bracelet. there no petition that you can sign to be against shorttermism. i tried to put one up and no one signed. it wa weird. but it prevents u from doing so much. shorttermism for many reason ha pervaded every nook and cranny of our reality. i just want you to take a second and just think about an issue that youre thinking working on. it could be personal it could be at work or it could be movetheneedle world stuff and think about how far out you tend to think about the solution set for that. because shorttermism prevents the ceo from buying really expensive safety equipment. itll hurt the bottom line. so we get the deepwater horizon. shorttermism prevents teacher from spending quality oneonone time with their student. so right now in america a high school student drop out every second. shorttermism prevents congress sorry if there anyone in here from congress or not really that sorry from putting money into a real infrastructure bill. so what we get is the iw bridge collapse over the mississippi a few year ago killed. it wasnt always like this. we did the panama canal. we pretty much have eradicated global polio. we did the transcontinental railroad the marshall plan. and it not just big physical infrastructure problem and issue. woman suffrage the right to vote. but in our shorttermist time where everything seems to happen right now and we can only think out past the next tweet or timeline post we get hyperreactionary. so what do we do. we take people who are fleeing their wartorn country and we go after them. we take lowlevel drug offender and we put them away for life. and then we build mcmansions without even thinking about how people are going to get between them and their job. it a quick buck. now the reality is for a lot of these problem there are some technical fix a lot of them. i call these technical fix sandbag strategy. so you know there a storm coming the levee is broken no one put any money into it you surround your home with sandbag. and guess what. it work. storm go away the water level go down you get rid of the sandbag and you do this storm after storm after storm. and here the insidious thing. a sandbag strategy can get you reelected. a sandbag strategy can help you make your quarterly number. now if we want to move forward into a different future than the one we have right now because i dont think weve hit is not peak civilization. there some more we can do. but my argument is that unless we shift our mental model and our mental map on how we think about the short it not going to happen. so what ive developed is something called longpath and it a practice. and longpath isnt a kind of oneanddone exercise. im sure everyone here at some point ha done an offsite with a lot of postit note and whiteboards and you do no offense to the consultant in here who do that and you do a longterm plan and then two week later everyone forgets about it. right. or a week later. if youre lucky three month. it a practice because it not necessarily a thing that you do. it a process where you have to revisit different way of thinking for every major decision that youre working on. so i want to go through those three way of thinking. so the first transgenerational thinking. i love the philosopher plato socrates habermas heidegger. i wa raised on them. but they all did one thing that didnt actually seem like a big deal until i really started kind of looking into this. and they all took a a unit of measure for their entire reality of what it meant to be virtuous and good the single lifespan from birth to death. but here a problem with these issue they stack up on top of u because the only way we know how to do something good in the world is if we do it between our birth and our death. thats what were programmed to do. if you go to the selfhelp section in any bookstore it all about you. which is great unless youre dealing with some of these major issue. and so with transgenerational thinking which is really kind of transgenerational ethic youre able to expand how you think about these problem what is your role in helping to solve them. now this isnt something that just ha to be done at the security council chamber. it something that you can do in a very kind of personal way. so every once in a while if im lucky my wife and i like to go out to dinner and we have three child under the age of seven. so you can imagine it a very peaceful quiet meal. so we sit down and literally all i want to do is just eat and chill and my kid have a completely and totally different idea of what were going to be doing. and so my first idea is my sandbag strategy right. it to go into my pocket and take out the iphone and give them frozen or some other bestselling game thing. and then i stop and i have to kind of put on this transgenerational thinking cap. i dont do this in the restaurant because it would be bizarre but i have to i did it once and thats how i learned it wa bizarre. and you have to kind of think ok i can do this. but what is this teaching them. so what doe it mean if i actually bring some paper or engage with them in conversation. it hard. it not easy and im making this very personal. it actually more traumatic than some of the big issue that i work on in the world entertaining my kid at dinner. but what it doe is it connects them here in the present with me but it also and this is the crux of transgenerational thinking ethic it set them up to how theyre going to interact with their kid and their kid and their kid. second future thinking. when we think about the future year out give me a vision of what the future is. you dont have to give it to me but think in your head. and what youre probably going to see is the dominant cultural lens that dominates our thinking about the future right now technology. so when we think about the problem we always put it through a technological lens a techcentric a technoutopia and there nothing wrong with that but it something that we have to really think deeply about if were going to move on these major issue because it wasnt always like this. right. the ancient had their way of thinking about what the future wa. the church definitely had their idea of what the future could be and you could actually pay your way into that future. right. and luckily for humanity we got the scientific revolution. from there we got the technology but what ha happened and by the way this is not a critique. i love technology. everything in my house talk back to me from my child to my speaker to everything. but weve abdicated the future from the high priest in rome to the high priest of silicon valley. so when we think well how are we going to deal with climate or with poverty or homelessness our first reaction is to think about it through a technology lens. and look im not advocating that we go to this guy. i love joel dont get me wrong but im not saying we go to joel. what im saying is we have to rethink our base assumption about only looking at the future in one way only looking at it through the dominant lens. because our problem are so big and so vast that we need to open ourselves up. so thats why i do everything in my power not to talk about the future. i talk about future. it open the conversation again. so when youre sitting and thinking about how do we move forward on this major issue it could be at home it could be at work it could be again on the global stage dont cut yourself off from thinking about something beyond technology a a fix because were more concerned about technological evolution right now than we are about moral evolution. and unless we fix for that were not going to be able to get out of shorttermism and get to where we want to be. the final telos thinking. this come from the greek root. ultimate aim and ultimate purpose. and it really asking one question to what end. when wa the last time you asked yourself to what end. and when you asked yourself that how far out did you go. because long isnt long enough anymore. three five year doesnt cut it. it year. in homer epic the odyssey odysseus had the answer to his what end. it wa ithaca. it wa this bold vision of what he wanted to return to penelope. and i can tell you because of the work that im doing but also you know it intuitively we have lost our ithaca. we have lost our to what end so we stay on this hamster wheel. and yes were trying to solve these problem but what come after we solve the problem. and unless you define what come after people arent going to move. the business this isnt just about business but the business that do consistently who break out of shorttermism not surprisingly are familyrun business. theyre transgenerational. theyre telos. they think about the future. and this is an ad for patek philippe. theyre year old and whats amazing is that they literally embody this kind of longpathian sense in their brand because by the way you never actually own a patek philippe and i definitely wont unless somebody want to just throw dollar on the stage. you merely look after it for the next generation. so it important that we remember the future we treat it like a noun. it not. it a verb. it requires action. it requires u to push into it. it not this thing that wash over u. it something that we actually have total control over. but in a shortterm society we end up feeling like we dont. we feel like were trapped. we can push through that. now im getting more comfortable in the fact that at some point in the inevitable future i will die. but because of these new way of thinking and doing both in the outside world and also with my family at home and what im leaving my kid i get more comfortable in that fact. and it something that a lot of u are really uncomfortable with but im telling you think it through. apply this type of thinking and you can push yourself past whats inevitably very very uncomfortable. and it all begin really with yourself asking this question what is your longpath. but i ask you when you ask yourself that now or tonight or behind a steering wheel or in the boardroom or the situation room push past the longpath quick oh whats my longpath the next three year or five year. try and push past your own life if you can because it make you do thing a little bit bigger than you thought were possible. yes we have huge huge problem out there. with this process with this thinking i think we can make a difference. i think you can make a difference and i believe in you guy'"
      ]
     },
     "execution_count": 506,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.iloc[2343].transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
