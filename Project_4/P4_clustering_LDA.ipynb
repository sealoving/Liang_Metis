{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2467\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comments</th>\n",
       "      <th>description</th>\n",
       "      <th>duration</th>\n",
       "      <th>event</th>\n",
       "      <th>film_date</th>\n",
       "      <th>languages</th>\n",
       "      <th>main_speaker</th>\n",
       "      <th>name</th>\n",
       "      <th>num_speaker</th>\n",
       "      <th>published_date</th>\n",
       "      <th>ratings</th>\n",
       "      <th>related_talks</th>\n",
       "      <th>speaker_occupation</th>\n",
       "      <th>tags</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>views</th>\n",
       "      <th>transcript</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4553</td>\n",
       "      <td>Sir Ken Robinson makes an entertaining and pro...</td>\n",
       "      <td>1164</td>\n",
       "      <td>TED2006</td>\n",
       "      <td>1140825600</td>\n",
       "      <td>60</td>\n",
       "      <td>Ken Robinson</td>\n",
       "      <td>Ken Robinson: Do schools kill creativity?</td>\n",
       "      <td>1</td>\n",
       "      <td>1151367060</td>\n",
       "      <td>[{'id': 7, 'name': 'Funny', 'count': 19645}, {...</td>\n",
       "      <td>[{'id': 865, 'hero': 'https://pe.tedcdn.com/im...</td>\n",
       "      <td>Author/educator</td>\n",
       "      <td>['children', 'creativity', 'culture', 'dance',...</td>\n",
       "      <td>Do schools kill creativity?</td>\n",
       "      <td>https://www.ted.com/talks/ken_robinson_says_sc...</td>\n",
       "      <td>47227110</td>\n",
       "      <td>it been great hasnt it. ive been blown away by...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   comments                                        description  duration  \\\n",
       "0      4553  Sir Ken Robinson makes an entertaining and pro...      1164   \n",
       "\n",
       "     event   film_date  languages  main_speaker  \\\n",
       "0  TED2006  1140825600         60  Ken Robinson   \n",
       "\n",
       "                                        name  num_speaker  published_date  \\\n",
       "0  Ken Robinson: Do schools kill creativity?            1      1151367060   \n",
       "\n",
       "                                             ratings  \\\n",
       "0  [{'id': 7, 'name': 'Funny', 'count': 19645}, {...   \n",
       "\n",
       "                                       related_talks speaker_occupation  \\\n",
       "0  [{'id': 865, 'hero': 'https://pe.tedcdn.com/im...    Author/educator   \n",
       "\n",
       "                                                tags  \\\n",
       "0  ['children', 'creativity', 'culture', 'dance',...   \n",
       "\n",
       "                         title  \\\n",
       "0  Do schools kill creativity?   \n",
       "\n",
       "                                                 url     views  \\\n",
       "0  https://www.ted.com/talks/ken_robinson_says_sc...  47227110   \n",
       "\n",
       "                                          transcript  \n",
       "0  it been great hasnt it. ive been blown away by...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all = pd.read_pickle('./data/df_all_lemma.pkl')\n",
    "print(len(df_all))\n",
    "df_all.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'only', 'oh', 'its', 'in', 'those', 'aren', 'needn', 'ma', \"won't\", 'does', 'herself', 'once', \"it's\", 'ok', 'shes', 'wasnt', 'is', 'hadn', 'ca', 'havent', 'okay', 'between', 'can', 'youll', 'neednt', 'ours', 'that', \"couldn't\", 'won', 'now', 'his', 'should', 'yourselves', 'your', 'so', 'had', \"wouldn't\", 'ill', 'myself', \"isn't\", 'itself', 'again', 'shouldn', 'mightnt', 'but', 'will', 'under', 'not', 'thatll', 'are', 'over', 'i', 'mr', 'did', 'further', 'being', \"don't\", \"haven't\", 'shant', 'a', 'ourselves', \"you're\", 'youre', 'wouldnt', 'above', \"wasn't\", 'whom', 'himself', 'into', 'shan', 'yourself', 'to', 'we', 'while', 's', 'at', 'isn', 'same', 'arent', 'until', 'up', 'doesn', 'haven', 'was', 'how', 'wasn', 'if', 'about', 'below', 'any', 'out', 'having', 'such', 'than', 'her', 'by', \"mustn't\", 'and', 'themselves', 'or', 'on', 'youve', 'th', 'ted', 'from', 'each', \"hasn't\", \"shouldn't\", 'were', 'all', 've', 'yeah', 'bg', 'against', 'down', 'em', 'dont', 'for', 'd', \"hadn't\", 'very', 'yours', \"you'd\", 'before', 'our', 'ms', 'their', 'ha', 'shouldnt', 'after', 'hasn', 'mustn', 'me', 'nor', \"shan't\", 'hasnt', 'mightn', 'which', 'shouldve', 'll', 't', \"you'll\", 'hers', 'during', 'when', 'youd', 'weren', 'o', \"mightn't\", 'it', 'then', 'too', 'hadnt', 'y', \"doesn't\", 're', 'other', 'why', 'm', \"didn't\", 'as', 'few', 'own', 'most', 'she', 'yes', 'who', 'do', 'he', 'more', 'my', 'you', 'didn', 'through', 'off', 'there', 'don', 'couldnt', 'because', 'da', 'him', 'couldn', \"you've\", 'with', 'might', 'where', 'mustnt', \"she's\", 'be', 'just', 'am', 'has', 'wouldn', 'werent', 'this', 'what', 'doing', 'have', 'an', 'didnt', \"aren't\", 'of', 'no', 'both', 'ain', 'theirs', 'these', 'here', 'some', \"needn't\", \"should've\", 'mrs', 'doesnt', 'been', \"weren't\", 'isnt', 'them', 'wont', 'they', \"that'll\"]\n"
     ]
    }
   ],
   "source": [
    "docs_all = list(df_all['transcript'])\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stops_standard = stopwords.words('english')\n",
    "stops_custom = ['shes','youll','ill','yeah','th','yes','oh',\n",
    "                'ok','okay','might','ha','mr','bg','ms',\n",
    "                'mrs','ca','em','da','ted']+[re.sub('[^A-Za-z ]+', '', w) for w in stops_standard]\n",
    "stop_list = list(set(stops_standard + stops_custom))\n",
    "\n",
    "print(stop_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting tf features for LDA...\n",
      "done in 2.623s.\n",
      "\n",
      "Fitting LDA models with tf features, n_samples=2000 and n_features=2000...\n",
      "done in 10.931s.\n",
      "\n",
      "Topics in LDA model:\n",
      "Topic #0: cancer blood patient tumor tissue surgery breast organ stem lung\n",
      "Topic #1: military fly department flight strategy capability russian intelligence moon boy\n",
      "Topic #2: ocean fish sea coral shark boat whale reef underwater island\n",
      "Topic #3: religion sugar religious moral dinosaur silk spider muslim tradition christian\n",
      "Topic #4: music stick listen gap please etc instrument musician tiny hall\n",
      "Topic #5: ah wow radio slide produce wind library crop dropped blow\n",
      "Topic #6: bread cow milk spread remarkable hot paint ad ingredient sell\n",
      "Topic #7: la boy de poem chose fresh busy written bringing curious\n",
      "Topic #8: online photo google paper page fun algorithm conversation card box\n",
      "Topic #9: evolution theory africa laptop memory prediction organism wish evolve digital\n",
      "Topic #10: cave mountain hidden ride continent mar covered exploration bacteria named\n",
      "Topic #11: patient drug doctor medical treatment hospital sex medicine trial hiv\n",
      "Topic #12: twitter evolution plant baby interface fly moral fire robot among\n",
      "Topic #13: dna gene genome virus molecule genetic code bacteria vaccine biology\n",
      "Topic #14: coal oil gas al clean warming alternative largest christmas biological\n",
      "Topic #15: lab leg object arm patent physical finger experiment ball engineer\n",
      "Topic #16: cancer muscle wikipedia twitter co article emission film tissue tumor\n",
      "Topic #17: emotion desire sad positive shape belief angry surprise variety contribute\n",
      "Topic #18: map ship satellite gold station rocket exploration horse mission route\n",
      "Topic #19: chinese china factory shoe worker oil largest pair maker north\n",
      "Topic #20: political rule democracy law institution election politics citizen trust knowledge\n",
      "Topic #21: universe star mar physic sun particle galaxy solar nuclear theory\n",
      "Topic #22: robot behavior neuron memory intelligence pattern experiment self monkey activity\n",
      "Topic #23: tail statistic error pattern explanation modern likely mathematical context britain\n",
      "Topic #24: baby bird song dog mom pregnant english birth iran sing\n",
      "Topic #25: specie tree forest climate plant carbon river land plastic soil\n",
      "Topic #26: eat weight diet eating fat meat healthy exercise meal lose\n",
      "Topic #27: artist architecture museum structure painting object pattern architect shape site\n",
      "Topic #28: music song dance playing listening listen poem player instrument musician\n",
      "Topic #29: aid poor poverty africa farmer net chimpanzee loan malaria fund\n",
      "Topic #30: happiness ice meaning stress flag pole positive joy snow self\n",
      "Topic #31: fly consciousness pm flight airplane flying drone wing plane pilot\n",
      "Topic #32: africa fire forest specie physical lab star rock mission revolution\n",
      "Topic #33: bee plant insect flower microscope crop apple sex fruit colony\n",
      "Topic #34: china factory landscape wish device patient signal attack electrical industry\n",
      "Topic #35: teacher class industry success math classroom teach farmer brand teaching\n",
      "Topic #36: electricity oil fuel innovation road waste vehicle clean mile per\n",
      "Topic #37: printing print volunteer press newspaper square sir plus please independent\n",
      "Topic #38: blog illusion dolphin evolution joke writing draw main choose reading\n",
      "Topic #39: ant worker colony bat rule queen interaction road pattern collective\n",
      "Topic #40: camera dictionary laptop english display soldier electronic unit recorded witness\n",
      "Topic #41: africa india economy economic growth african china europe income per\n",
      "Topic #42: boy violence police leader truth son refugee prison conversation compassion\n",
      "Topic #43: player india toy bus bird response flu legal creature neighborhood\n",
      "Topic #44: notion fuel cooking waste burn architecture led tree etc village\n",
      "Topic #45: aid gang political south capital civil assumption economy afghanistan poor\n",
      "Topic #46: penguin designer adam object chair plant david garden designed fashion\n",
      "Topic #47: limb load muscle strike bubble period spring soft biological pound\n",
      "Topic #48: network digital device surveillance service online software web mobile send\n",
      "Topic #49: cartoon normal laugh character drawing town target please office worth\n",
      "\n"
     ]
    }
   ],
   "source": [
    "docs = docs_all\n",
    "\n",
    "from time import time\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "\n",
    "n_samples = 2000\n",
    "n_features = 2000\n",
    "n_components = 50\n",
    "n_top_words = 10\n",
    "n_gram = 1\n",
    "alpha = 0.1\n",
    "stop_choice= stop_list\n",
    "\n",
    "max_df = 400\n",
    "min_df = 10\n",
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        message = \"Topic #%d: \" % topic_idx\n",
    "        message += \" \".join([feature_names[i]\n",
    "                             for i in topic.argsort()[:-n_top_words - 1:-1]])\n",
    "        print(message)\n",
    "    print()\n",
    "\n",
    "\n",
    "# Use tf (raw term count) features for LDA.\n",
    "print(\"Extracting tf features for LDA...\")\n",
    "tf_vectorizer = CountVectorizer(max_df=max_df, min_df=min_df,\n",
    "                                ngram_range=(n_gram,n_gram),\n",
    "                                max_features=n_features,\n",
    "                                stop_words=stop_choice)\n",
    "t0 = time()\n",
    "tf = tf_vectorizer.fit_transform(docs)\n",
    "print(\"done in %0.3fs.\" % (time() - t0))\n",
    "print()\n",
    "\n",
    "# Fit the LDA model\n",
    "print(\"Fitting LDA models with tf features, \"\n",
    "      \"n_samples=%d and n_features=%d...\"\n",
    "      % (n_samples, n_features))\n",
    "lda = LatentDirichletAllocation(n_components=n_components, max_iter=5,\n",
    "                                learning_method='online',\n",
    "                                learning_offset=50.,\n",
    "                                random_state=0)\n",
    "t0 = time()\n",
    "lda.fit(tf)\n",
    "print(\"done in %0.3fs.\" % (time() - t0))\n",
    "\n",
    "print(\"\\nTopics in LDA model:\")\n",
    "tf_feature_names = tf_vectorizer.get_feature_names()\n",
    "print_top_words(lda, tf_feature_names, n_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = lda.fit_transform(tf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[134].argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find related talks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn.neighbors.kd_tree as kdtree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 \t A prosthetic arm that \"feels\"\n",
      "2146 \t This scientist makes ears out of apples\n",
      "1787 \t This gel can make you stop bleeding instantly\n",
      "1554 \t Body parts on a chip\n",
      "1126 \t On the virtual dissection table\n",
      "2400 \t Lifesaving scientific tools made of paper\n",
      "1177 \t What we didn't know about penis anatomy\n",
      "2195 \t Why helmets don't prevent concussions -- and what might\n",
      "859 \t Human exoskeletons -- for war and healing\n",
      "228 \t Moving sculpture\n",
      "248 \t Animate characters by evolving them\n",
      "1378 \t Play with smart materials\n",
      "589 \t A lab the size of a postage stamp\n",
      "815 \t Visualizing the medical data explosion\n",
      "1566 \t The $80 prosthetic knee that's changing lives\n",
      "1013 \t High-tech art (with a sense of humor)\n",
      "668 \t Pointing to the future of UI\n",
      "705 \t The bio-future of joint replacement\n",
      "1629 \t The new bionics that let us run, climb and dance\n",
      "938 \t Caring for engineered tissue\n"
     ]
    }
   ],
   "source": [
    "tree = kdtree.KDTree(X, leaf_size=10) \n",
    "N = 1000\n",
    "dist, ind = tree.query([X[N]], k=20)  \n",
    "for i in ind[0]:\n",
    "    print(i,'\\t',df_all.iloc[i].title)\n",
    "#     print(i,'\\t',df_all.iloc[i].views)\n",
    "#     print(df_all.iloc[i].tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['My 12 pairs of legs']\n",
      "['Luke, a new prosthetic arm for soldiers']\n",
      "['The potential of regenerative medicine']\n",
      "['The mystery of chronic pain']\n",
      "['The emotion behind invention']\n",
      "['3 clues to understanding your brain']\n"
     ]
    }
   ],
   "source": [
    "df_related = pd.DataFrame(eval(df_all.iloc[N]['related_talks']))\n",
    "for k in range(len(df_related)):\n",
    "    print(list(df_all[df_all['title']==df_related.iloc[k]['title']].title))\n",
    "#     print(df_all[df_all['title']==df_related.iloc[k]['title']].views)\n",
    "#     print(list(df_all[df_all['title']==df_related.iloc[k]['title']].tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# print(docs_all[395])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering using KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn import cluster\n",
    "\n",
    "n_clusters = 50\n",
    "\n",
    "# ward = cluster.AgglomerativeClustering(\n",
    "#     n_clusters=n_clusters, linkage='ward',\n",
    "#     connectivity=connectivity)\n",
    "spectral = cluster.SpectralClustering(\n",
    "    n_clusters=n_clusters, eigen_solver='arpack',\n",
    "    affinity=\"nearest_neighbors\")\n",
    "Xp = spectral.fit_predict(X)\n",
    "# dbscan = cluster.DBSCAN(eps=params['eps'])\n",
    "\n",
    "# km = KMeans(n_clusters=50)\n",
    "# Xt = km.fit_transform(X)\n",
    "\n",
    "# mu_docs = km.cluster_centers_\n",
    "# plt.plot(mu_docs.transpose())\n",
    "\n",
    "# silhouette_score(X, km.labels_, metric='euclidean')\n",
    "\n",
    "# sil_scores = []\n",
    "# iner_scores = []\n",
    "# ks = range(2,20)\n",
    "# for k in ks:\n",
    "#     km = KMeans(n_clusters=k)\n",
    "#     km.fit(X)\n",
    "#     sil_scores.append(silhouette_score(X, km.labels_, metric='euclidean'))\n",
    "#     iner_scores.append(km.inertia_)\n",
    "    \n",
    "# plt.plot(ks,sil_scores)\n",
    "# plt.plot(ks,iner_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([18, 29, 18, ..., 28, 18, 10], dtype=int32)"
      ]
     },
     "execution_count": 510,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1599 \t Love -- you're doing it wrong\n",
      "2343 \t 3 ways to plan for the (very) long term\n",
      "2085 \t How to get back to work after a career break\n",
      "1395 \t What makes us feel good about our work?\n",
      "1135 \t How I beat a patent troll\n",
      "1872 \t How equal do we want the world to be? You'd be surprised\n",
      "1821 \t The danger of hiding who you are\n",
      "1870 \t 5 ways to kill your dreams\n",
      "1566 \t The $80 prosthetic knee that's changing lives\n",
      "609 \t Plug into your hard-wired happiness\n"
     ]
    }
   ],
   "source": [
    "tree = kdtree.KDTree(Xt, leaf_size=10) \n",
    "# N = 1346\n",
    "dist, ind = tree.query([Xt[N]], k=10)  \n",
    "for i in ind[0]:\n",
    "    print(i,'\\t',df_all.iloc[i].title)\n",
    "#     print(i,'\\t',df_all.iloc[i].views)\n",
    "#     print(df_all.iloc[i].tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'and theyd say great. and ive been seeing that time horizon get shorter and shorter and shorter so much so that i met with a ceo two month ago and i said we started our initial conversation. he go i love what you do. i want to talk about the next six month. we have a lot of problem that we are facing. these are civilizationalscale problem. the issue though is we cant solve them using the mental model that we use right now to try and solve these problem. yes a lot of great technical work is being done but there is a problem that we need to solve for a priori before if we want to really move the needle on those big problem. shorttermism. right. there no march. there no bracelet. there no petition that you can sign to be against shorttermism. i tried to put one up and no one signed. it wa weird. but it prevents u from doing so much. shorttermism for many reason ha pervaded every nook and cranny of our reality. i just want you to take a second and just think about an issue that youre thinking working on. it could be personal it could be at work or it could be movetheneedle world stuff and think about how far out you tend to think about the solution set for that. because shorttermism prevents the ceo from buying really expensive safety equipment. itll hurt the bottom line. so we get the deepwater horizon. shorttermism prevents teacher from spending quality oneonone time with their student. so right now in america a high school student drop out every second. shorttermism prevents congress sorry if there anyone in here from congress or not really that sorry from putting money into a real infrastructure bill. so what we get is the iw bridge collapse over the mississippi a few year ago killed. it wasnt always like this. we did the panama canal. we pretty much have eradicated global polio. we did the transcontinental railroad the marshall plan. and it not just big physical infrastructure problem and issue. woman suffrage the right to vote. but in our shorttermist time where everything seems to happen right now and we can only think out past the next tweet or timeline post we get hyperreactionary. so what do we do. we take people who are fleeing their wartorn country and we go after them. we take lowlevel drug offender and we put them away for life. and then we build mcmansions without even thinking about how people are going to get between them and their job. it a quick buck. now the reality is for a lot of these problem there are some technical fix a lot of them. i call these technical fix sandbag strategy. so you know there a storm coming the levee is broken no one put any money into it you surround your home with sandbag. and guess what. it work. storm go away the water level go down you get rid of the sandbag and you do this storm after storm after storm. and here the insidious thing. a sandbag strategy can get you reelected. a sandbag strategy can help you make your quarterly number. now if we want to move forward into a different future than the one we have right now because i dont think weve hit is not peak civilization. there some more we can do. but my argument is that unless we shift our mental model and our mental map on how we think about the short it not going to happen. so what ive developed is something called longpath and it a practice. and longpath isnt a kind of oneanddone exercise. im sure everyone here at some point ha done an offsite with a lot of postit note and whiteboards and you do no offense to the consultant in here who do that and you do a longterm plan and then two week later everyone forgets about it. right. or a week later. if youre lucky three month. it a practice because it not necessarily a thing that you do. it a process where you have to revisit different way of thinking for every major decision that youre working on. so i want to go through those three way of thinking. so the first transgenerational thinking. i love the philosopher plato socrates habermas heidegger. i wa raised on them. but they all did one thing that didnt actually seem like a big deal until i really started kind of looking into this. and they all took a a unit of measure for their entire reality of what it meant to be virtuous and good the single lifespan from birth to death. but here a problem with these issue they stack up on top of u because the only way we know how to do something good in the world is if we do it between our birth and our death. thats what were programmed to do. if you go to the selfhelp section in any bookstore it all about you. which is great unless youre dealing with some of these major issue. and so with transgenerational thinking which is really kind of transgenerational ethic youre able to expand how you think about these problem what is your role in helping to solve them. now this isnt something that just ha to be done at the security council chamber. it something that you can do in a very kind of personal way. so every once in a while if im lucky my wife and i like to go out to dinner and we have three child under the age of seven. so you can imagine it a very peaceful quiet meal. so we sit down and literally all i want to do is just eat and chill and my kid have a completely and totally different idea of what were going to be doing. and so my first idea is my sandbag strategy right. it to go into my pocket and take out the iphone and give them frozen or some other bestselling game thing. and then i stop and i have to kind of put on this transgenerational thinking cap. i dont do this in the restaurant because it would be bizarre but i have to i did it once and thats how i learned it wa bizarre. and you have to kind of think ok i can do this. but what is this teaching them. so what doe it mean if i actually bring some paper or engage with them in conversation. it hard. it not easy and im making this very personal. it actually more traumatic than some of the big issue that i work on in the world entertaining my kid at dinner. but what it doe is it connects them here in the present with me but it also and this is the crux of transgenerational thinking ethic it set them up to how theyre going to interact with their kid and their kid and their kid. second future thinking. when we think about the future year out give me a vision of what the future is. you dont have to give it to me but think in your head. and what youre probably going to see is the dominant cultural lens that dominates our thinking about the future right now technology. so when we think about the problem we always put it through a technological lens a techcentric a technoutopia and there nothing wrong with that but it something that we have to really think deeply about if were going to move on these major issue because it wasnt always like this. right. the ancient had their way of thinking about what the future wa. the church definitely had their idea of what the future could be and you could actually pay your way into that future. right. and luckily for humanity we got the scientific revolution. from there we got the technology but what ha happened and by the way this is not a critique. i love technology. everything in my house talk back to me from my child to my speaker to everything. but weve abdicated the future from the high priest in rome to the high priest of silicon valley. so when we think well how are we going to deal with climate or with poverty or homelessness our first reaction is to think about it through a technology lens. and look im not advocating that we go to this guy. i love joel dont get me wrong but im not saying we go to joel. what im saying is we have to rethink our base assumption about only looking at the future in one way only looking at it through the dominant lens. because our problem are so big and so vast that we need to open ourselves up. so thats why i do everything in my power not to talk about the future. i talk about future. it open the conversation again. so when youre sitting and thinking about how do we move forward on this major issue it could be at home it could be at work it could be again on the global stage dont cut yourself off from thinking about something beyond technology a a fix because were more concerned about technological evolution right now than we are about moral evolution. and unless we fix for that were not going to be able to get out of shorttermism and get to where we want to be. the final telos thinking. this come from the greek root. ultimate aim and ultimate purpose. and it really asking one question to what end. when wa the last time you asked yourself to what end. and when you asked yourself that how far out did you go. because long isnt long enough anymore. three five year doesnt cut it. it year. in homer epic the odyssey odysseus had the answer to his what end. it wa ithaca. it wa this bold vision of what he wanted to return to penelope. and i can tell you because of the work that im doing but also you know it intuitively we have lost our ithaca. we have lost our to what end so we stay on this hamster wheel. and yes were trying to solve these problem but what come after we solve the problem. and unless you define what come after people arent going to move. the business this isnt just about business but the business that do consistently who break out of shorttermism not surprisingly are familyrun business. theyre transgenerational. theyre telos. they think about the future. and this is an ad for patek philippe. theyre year old and whats amazing is that they literally embody this kind of longpathian sense in their brand because by the way you never actually own a patek philippe and i definitely wont unless somebody want to just throw dollar on the stage. you merely look after it for the next generation. so it important that we remember the future we treat it like a noun. it not. it a verb. it requires action. it requires u to push into it. it not this thing that wash over u. it something that we actually have total control over. but in a shortterm society we end up feeling like we dont. we feel like were trapped. we can push through that. now im getting more comfortable in the fact that at some point in the inevitable future i will die. but because of these new way of thinking and doing both in the outside world and also with my family at home and what im leaving my kid i get more comfortable in that fact. and it something that a lot of u are really uncomfortable with but im telling you think it through. apply this type of thinking and you can push yourself past whats inevitably very very uncomfortable. and it all begin really with yourself asking this question what is your longpath. but i ask you when you ask yourself that now or tonight or behind a steering wheel or in the boardroom or the situation room push past the longpath quick oh whats my longpath the next three year or five year. try and push past your own life if you can because it make you do thing a little bit bigger than you thought were possible. yes we have huge huge problem out there. with this process with this thinking i think we can make a difference. i think you can make a difference and i believe in you guy'"
      ]
     },
     "execution_count": 506,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.iloc[2343].transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
