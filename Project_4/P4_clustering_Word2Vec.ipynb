{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from time import time\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2524\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comments</th>\n",
       "      <th>description</th>\n",
       "      <th>duration</th>\n",
       "      <th>event</th>\n",
       "      <th>film_date</th>\n",
       "      <th>languages</th>\n",
       "      <th>link</th>\n",
       "      <th>main_speaker</th>\n",
       "      <th>name</th>\n",
       "      <th>num_speaker</th>\n",
       "      <th>published_date</th>\n",
       "      <th>ratings</th>\n",
       "      <th>related_talks</th>\n",
       "      <th>speaker_occupation</th>\n",
       "      <th>tags</th>\n",
       "      <th>title</th>\n",
       "      <th>transcript</th>\n",
       "      <th>url</th>\n",
       "      <th>views</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4553.0</td>\n",
       "      <td>Sir Ken Robinson makes an entertaining and pro...</td>\n",
       "      <td>1164.0</td>\n",
       "      <td>TED2006</td>\n",
       "      <td>1.140826e+09</td>\n",
       "      <td>60.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ken Robinson</td>\n",
       "      <td>Ken Robinson: Do schools kill creativity?</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.151367e+09</td>\n",
       "      <td>[{'id': 7, 'name': 'Funny', 'count': 19645}, {...</td>\n",
       "      <td>[{'id': 865, 'hero': 'https://pe.tedcdn.com/im...</td>\n",
       "      <td>Author/educator</td>\n",
       "      <td>['children', 'creativity', 'culture', 'dance',...</td>\n",
       "      <td>Do schools kill creativity?</td>\n",
       "      <td>it been great hasnt it. ive been blown away by...</td>\n",
       "      <td>https://www.ted.com/talks/ken_robinson_says_sc...</td>\n",
       "      <td>47227110.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   comments                                        description  duration  \\\n",
       "0    4553.0  Sir Ken Robinson makes an entertaining and pro...    1164.0   \n",
       "\n",
       "     event     film_date  languages link  main_speaker  \\\n",
       "0  TED2006  1.140826e+09       60.0  NaN  Ken Robinson   \n",
       "\n",
       "                                        name  num_speaker  published_date  \\\n",
       "0  Ken Robinson: Do schools kill creativity?          1.0    1.151367e+09   \n",
       "\n",
       "                                             ratings  \\\n",
       "0  [{'id': 7, 'name': 'Funny', 'count': 19645}, {...   \n",
       "\n",
       "                                       related_talks speaker_occupation  \\\n",
       "0  [{'id': 865, 'hero': 'https://pe.tedcdn.com/im...    Author/educator   \n",
       "\n",
       "                                                tags  \\\n",
       "0  ['children', 'creativity', 'culture', 'dance',...   \n",
       "\n",
       "                         title  \\\n",
       "0  Do schools kill creativity?   \n",
       "\n",
       "                                          transcript  \\\n",
       "0  it been great hasnt it. ive been blown away by...   \n",
       "\n",
       "                                                 url       views  \n",
       "0  https://www.ted.com/talks/ken_robinson_says_sc...  47227110.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all = pd.read_pickle('./data/df_all_lemma.pkl')\n",
    "print(len(df_all))\n",
    "df_all.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_all = list(df_all['transcript'])\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stops_standard = stopwords.words('english')\n",
    "stops_custom = ['shes','youll','ill','yeah','th','yes','oh',\n",
    "                'ok','okay','might','ha','mr','bg','ms',\n",
    "                'mrs','ca','em','da','ted','pm','hey','al']+[re.sub('[^A-Za-z ]+', '', w) for w in stops_standard]\n",
    "stop_list = list(set(stops_standard + stops_custom))\n",
    "\n",
    "# print(stop_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "documents = docs_all\n",
    "\n",
    "# The type of input that Word2Vec is looking for.. \n",
    "# is a list of sentences\n",
    "# and, each sentence is a list of words\n",
    "sentences = []\n",
    "for document in documents:\n",
    "    texts = [[word for word in sent.split() if word not in stop_list]\n",
    "         for sent in document.split('.')]\n",
    "    sentences += texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['great'],\n",
       " ['ive', 'blown', 'away', 'whole', 'thing'],\n",
       " ['fact', 'im', 'leaving'],\n",
       " ['three', 'theme', 'running', 'conference', 'relevant', 'want', 'talk'],\n",
       " ['one',\n",
       "  'extraordinary',\n",
       "  'evidence',\n",
       "  'human',\n",
       "  'creativity',\n",
       "  'presentation',\n",
       "  'weve',\n",
       "  'people'],\n",
       " ['variety', 'range']]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 29.905s.\n"
     ]
    }
   ],
   "source": [
    "import gensim  # using skip-gram\n",
    "t0 = time()\n",
    "model_TED = gensim.models.Word2Vec(sentences, size=50, window=5, min_count=1, workers=2,sg=1)\n",
    "print(\"done in %0.3fs.\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = model_TED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('great', <gensim.models.keyedvectors.Vocab at 0x119038390>),\n",
       " ('ive', <gensim.models.keyedvectors.Vocab at 0x1190385c0>),\n",
       " ('blown', <gensim.models.keyedvectors.Vocab at 0x119abcf60>),\n",
       " ('away', <gensim.models.keyedvectors.Vocab at 0x119bb8f28>),\n",
       " ('whole', <gensim.models.keyedvectors.Vocab at 0x119c06630>)]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.wv.vocab.items())[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('musical', 0.8442516326904297),\n",
       " ('violin', 0.8293101787567139),\n",
       " ('classical', 0.8263627886772156),\n",
       " ('beethoven', 0.8191320896148682),\n",
       " ('poetry', 0.8143652081489563),\n",
       " ('musician', 0.814338207244873),\n",
       " ('jazz', 0.8098499774932861),\n",
       " ('symphony', 0.8035442233085632),\n",
       " ('rap', 0.8035263419151306),\n",
       " ('improvise', 0.8016418814659119)]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('music', topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7551180308241303"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity('cancer','patient')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define coherence score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def coherence_score(words, model):\n",
    "    X = []\n",
    "    for word in words:\n",
    "        X.append(model.wv.__getitem__(word))\n",
    "    score = cosine_similarity(X, Y=None, dense_output=True)\n",
    "    return score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_coherence_score(df, model):\n",
    "    scores = []\n",
    "    for i in range(len(df)):\n",
    "        words = list(df.iloc[i,:])\n",
    "        scores.append(coherence_score(words, model))\n",
    "    df['score'] = scores\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load top words in LSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>city</td>\n",
       "      <td>brain</td>\n",
       "      <td>data</td>\n",
       "      <td>water</td>\n",
       "      <td>community</td>\n",
       "      <td>design</td>\n",
       "      <td>book</td>\n",
       "      <td>company</td>\n",
       "      <td>space</td>\n",
       "      <td>computer</td>\n",
       "      <td>0.526897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>brain</td>\n",
       "      <td>cell</td>\n",
       "      <td>animal</td>\n",
       "      <td>planet</td>\n",
       "      <td>water</td>\n",
       "      <td>cancer</td>\n",
       "      <td>earth</td>\n",
       "      <td>robot</td>\n",
       "      <td>universe</td>\n",
       "      <td>light</td>\n",
       "      <td>0.566468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>city</td>\n",
       "      <td>water</td>\n",
       "      <td>planet</td>\n",
       "      <td>energy</td>\n",
       "      <td>ocean</td>\n",
       "      <td>earth</td>\n",
       "      <td>climate</td>\n",
       "      <td>space</td>\n",
       "      <td>oil</td>\n",
       "      <td>sea</td>\n",
       "      <td>0.616479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cancer</td>\n",
       "      <td>cell</td>\n",
       "      <td>patient</td>\n",
       "      <td>disease</td>\n",
       "      <td>health</td>\n",
       "      <td>drug</td>\n",
       "      <td>government</td>\n",
       "      <td>africa</td>\n",
       "      <td>dollar</td>\n",
       "      <td>data</td>\n",
       "      <td>0.578982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data</td>\n",
       "      <td>computer</td>\n",
       "      <td>robot</td>\n",
       "      <td>information</td>\n",
       "      <td>machine</td>\n",
       "      <td>company</td>\n",
       "      <td>design</td>\n",
       "      <td>internet</td>\n",
       "      <td>government</td>\n",
       "      <td>phone</td>\n",
       "      <td>0.634560</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1        2            3          4        5           6  \\\n",
       "0    city     brain     data        water  community   design        book   \n",
       "1   brain      cell   animal       planet      water   cancer       earth   \n",
       "2    city     water   planet       energy      ocean    earth     climate   \n",
       "3  cancer      cell  patient      disease     health     drug  government   \n",
       "4    data  computer    robot  information    machine  company      design   \n",
       "\n",
       "          7           8         9     score  \n",
       "0   company       space  computer  0.526897  \n",
       "1     robot    universe     light  0.566468  \n",
       "2     space         oil       sea  0.616479  \n",
       "3    africa      dollar      data  0.578982  \n",
       "4  internet  government     phone  0.634560  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle('./data/LSA_top_words.pkl')\n",
    "df = add_coherence_score(df, model)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5125746852159501"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        0        1        2    3     4       5      6         7      8    9  \\\n",
      "48  space  refugee  project  oil  song  choice  water  election  voice  fly   \n",
      "\n",
      "       score  \n",
      "48  0.455973  \n",
      "      0       1       2        3     4    5             6       7  \\\n",
      "5  city  design  cancer  patient  cell  car  architecture  street   \n",
      "\n",
      "              8      9     score  \n",
      "5  neighborhood  space  0.565399  \n",
      "      0         1      2            3        4        5       6         7  \\\n",
      "4  data  computer  robot  information  machine  company  design  internet   \n",
      "\n",
      "            8      9    score  \n",
      "4  government  phone  0.63456  \n"
     ]
    }
   ],
   "source": [
    "print(df[df.score==df.score.sort_values().iloc[0]])\n",
    "print(df[df.score==df.score.sort_values().iloc[42]])\n",
    "print(df[df.score==df.score.sort_values().iloc[49]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load top words in LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>limb</td>\n",
       "      <td>animal</td>\n",
       "      <td>force</td>\n",
       "      <td>muscle</td>\n",
       "      <td>spring</td>\n",
       "      <td>frame</td>\n",
       "      <td>per</td>\n",
       "      <td>video</td>\n",
       "      <td>movement</td>\n",
       "      <td>surface</td>\n",
       "      <td>0.527451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>energy</td>\n",
       "      <td>car</td>\n",
       "      <td>oil</td>\n",
       "      <td>climate</td>\n",
       "      <td>product</td>\n",
       "      <td>water</td>\n",
       "      <td>fuel</td>\n",
       "      <td>carbon</td>\n",
       "      <td>city</td>\n",
       "      <td>per</td>\n",
       "      <td>0.591174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>south</td>\n",
       "      <td>community</td>\n",
       "      <td>city</td>\n",
       "      <td>environmental</td>\n",
       "      <td>development</td>\n",
       "      <td>waste</td>\n",
       "      <td>economic</td>\n",
       "      <td>common</td>\n",
       "      <td>park</td>\n",
       "      <td>dog</td>\n",
       "      <td>0.544578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>baby</td>\n",
       "      <td>mother</td>\n",
       "      <td>pregnant</td>\n",
       "      <td>mom</td>\n",
       "      <td>birth</td>\n",
       "      <td>milk</td>\n",
       "      <td>awesome</td>\n",
       "      <td>born</td>\n",
       "      <td>amazing</td>\n",
       "      <td>box</td>\n",
       "      <td>0.619164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>united</td>\n",
       "      <td>men</td>\n",
       "      <td>paper</td>\n",
       "      <td>black</td>\n",
       "      <td>data</td>\n",
       "      <td>per</td>\n",
       "      <td>statistic</td>\n",
       "      <td>everybody</td>\n",
       "      <td>india</td>\n",
       "      <td>nice</td>\n",
       "      <td>0.515619</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0          1         2              3            4      5          6  \\\n",
       "0    limb     animal     force         muscle       spring  frame        per   \n",
       "1  energy        car       oil        climate      product  water       fuel   \n",
       "2   south  community      city  environmental  development  waste   economic   \n",
       "3    baby     mother  pregnant            mom        birth   milk    awesome   \n",
       "4  united        men     paper          black         data    per  statistic   \n",
       "\n",
       "           7         8        9     score  \n",
       "0      video  movement  surface  0.527451  \n",
       "1     carbon      city      per  0.591174  \n",
       "2     common      park      dog  0.544578  \n",
       "3       born   amazing      box  0.619164  \n",
       "4  everybody     india     nice  0.515619  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle('./data/LDA_top_words.pkl')\n",
    "df = add_coherence_score(df, model)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6049833065271377"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         0          1     2      3      4         5        6     7    8     9  \\\n",
      "44  design  happiness  gene  force  happy  designer  project  code  war  york   \n",
      "\n",
      "       score  \n",
      "44  0.484899  \n",
      "           0      1       2           3           4      5        6       7  \\\n",
      "37  disorder  brain  device  disability  electrical  light  circuit  neuron   \n",
      "\n",
      "       8       9     score  \n",
      "37  gold  signal  0.598363  \n",
      "        0        1        2         3        4        5           6    7  \\\n",
      "25  virus  disease  vaccine  mosquito  microbe  malaria  antibiotic  hiv   \n",
      "\n",
      "            8         9     score  \n",
      "25  infection  organism  0.778051  \n"
     ]
    }
   ],
   "source": [
    "print(df[df.score==df.score.sort_values().iloc[0]])\n",
    "print(df[df.score==df.score.sort_values().iloc[25]])\n",
    "print(df[df.score==df.score.sort_values().iloc[49]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load top words in NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>book</td>\n",
       "      <td>felt</td>\n",
       "      <td>learned</td>\n",
       "      <td>night</td>\n",
       "      <td>read</td>\n",
       "      <td>somebody</td>\n",
       "      <td>everybody</td>\n",
       "      <td>age</td>\n",
       "      <td>feeling</td>\n",
       "      <td>name</td>\n",
       "      <td>0.559617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dna</td>\n",
       "      <td>gene</td>\n",
       "      <td>genome</td>\n",
       "      <td>genetic</td>\n",
       "      <td>bacteria</td>\n",
       "      <td>virus</td>\n",
       "      <td>specie</td>\n",
       "      <td>sequence</td>\n",
       "      <td>molecule</td>\n",
       "      <td>organism</td>\n",
       "      <td>0.766341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>energy</td>\n",
       "      <td>nuclear</td>\n",
       "      <td>climate</td>\n",
       "      <td>fuel</td>\n",
       "      <td>solar</td>\n",
       "      <td>carbon</td>\n",
       "      <td>electricity</td>\n",
       "      <td>coal</td>\n",
       "      <td>emission</td>\n",
       "      <td>co</td>\n",
       "      <td>0.744357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>drug</td>\n",
       "      <td>disease</td>\n",
       "      <td>vaccine</td>\n",
       "      <td>virus</td>\n",
       "      <td>hiv</td>\n",
       "      <td>treatment</td>\n",
       "      <td>epidemic</td>\n",
       "      <td>trial</td>\n",
       "      <td>flu</td>\n",
       "      <td>health</td>\n",
       "      <td>0.738638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>computer</td>\n",
       "      <td>software</td>\n",
       "      <td>code</td>\n",
       "      <td>algorithm</td>\n",
       "      <td>device</td>\n",
       "      <td>digital</td>\n",
       "      <td>program</td>\n",
       "      <td>learning</td>\n",
       "      <td>interface</td>\n",
       "      <td>mit</td>\n",
       "      <td>0.721945</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1        2          3         4          5            6  \\\n",
       "0      book      felt  learned      night      read   somebody    everybody   \n",
       "1       dna      gene   genome    genetic  bacteria      virus       specie   \n",
       "2    energy   nuclear  climate       fuel     solar     carbon  electricity   \n",
       "3      drug   disease  vaccine      virus       hiv  treatment     epidemic   \n",
       "4  computer  software     code  algorithm    device    digital      program   \n",
       "\n",
       "          7          8         9     score  \n",
       "0       age    feeling      name  0.559617  \n",
       "1  sequence   molecule  organism  0.766341  \n",
       "2      coal   emission        co  0.744357  \n",
       "3     trial        flu    health  0.738638  \n",
       "4  learning  interface       mit  0.721945  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle('./data/NMF_top_words.pkl')\n",
    "df = add_coherence_score(df, model)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6792611867189408"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       0      1    2        3    4     5         6      7        8        9  \\\n",
      "48  song  cause  eye  nervous  dog  lady  feedback  stage  freedom  brother   \n",
      "\n",
      "       score  \n",
      "48  0.497786  \n",
      "     0        1         2         3            4       5         6      7  \\\n",
      "9  war  soldier  violence  conflict  afghanistan  weapon  military  peace   \n",
      "\n",
      "      8       9     score  \n",
      "9  iraq  killed  0.685777  \n",
      "       0    1       2         3       4       5       6        7        8  \\\n",
      "12  girl  boy  father  daughter  parent  sister  mother  village  brother   \n",
      "\n",
      "      9     score  \n",
      "12  mom  0.802257  \n"
     ]
    }
   ],
   "source": [
    "print(df[df.score==df.score.sort_values().iloc[0]])\n",
    "print(df[df.score==df.score.sort_values().iloc[25]])\n",
    "print(df[df.score==df.score.sort_values().iloc[49]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* How to define the distances between documents based on the distance in Word2Vec?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compute distance of documents based on Word2Vec distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.08427628  0.41684142  0.1274766   0.7023802  -0.24573441 -0.98860013\n",
      " -0.19132812 -1.340887    0.7664083  -0.2512282  -0.43190917 -0.34973925\n",
      "  0.60535854  0.5943859   0.08217657  1.4236348   0.32969564 -0.33111274\n",
      "  0.6941277  -0.36479068 -0.679587    0.03300359 -1.0456446  -0.039244\n",
      "  0.01228642 -0.01916472 -0.02262634  0.2942768   1.0078477  -0.03259582\n",
      " -0.20192716 -0.226965    0.5375818  -0.2982899   0.5816015   0.61463493\n",
      " -0.62001    -0.27787384 -0.19369034  0.3244977   0.64259297 -0.32401383\n",
      "  0.32126945  0.04915848  0.62995416 -0.3642654   0.4645366   0.01334787\n",
      "  0.44673425 -0.36006624]\n"
     ]
    }
   ],
   "source": [
    "print (model.wv.__getitem__('climate'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('warming', 0.8560107350349426),\n",
       " ('catastrophe', 0.824532151222229),\n",
       " ('desertification', 0.8010308742523193),\n",
       " ('overfishing', 0.8002601861953735),\n",
       " ('disruption', 0.7989152669906616),\n",
       " ('mitigate', 0.7943692803382874),\n",
       " ('twodegree', 0.7937451601028442),\n",
       " ('intergovernmental', 0.7863591313362122),\n",
       " ('deforestation', 0.7849549651145935),\n",
       " ('urbanization', 0.7847277522087097),\n",
       " ('acidification', 0.7834381461143494),\n",
       " ('environmental', 0.7807230949401855),\n",
       " ('polarization', 0.7777093052864075),\n",
       " ('unsustainable', 0.7770941257476807),\n",
       " ('inequity', 0.7729911804199219),\n",
       " ('catastrophic', 0.7727354764938354),\n",
       " ('gradual', 0.7710027694702148),\n",
       " ('drought', 0.7710023522377014),\n",
       " ('global', 0.7686222791671753),\n",
       " ('gridlock', 0.7665075063705444),\n",
       " ('degradation', 0.7637777924537659),\n",
       " ('crisis', 0.762445867061615),\n",
       " ('governance', 0.7578604221343994),\n",
       " ('lowcarbon', 0.7562432289123535),\n",
       " ('hunger', 0.7543408274650574),\n",
       " ('brink', 0.7516579627990723),\n",
       " ('systemic', 0.7506305575370789),\n",
       " ('dramatically', 0.7471637725830078),\n",
       " ('macro', 0.7465881109237671),\n",
       " ('biodiversity', 0.7456514239311218)]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('climate', topn=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['absolute',\n",
       " 'abstract',\n",
       " 'abuse',\n",
       " 'academic',\n",
       " 'accept',\n",
       " 'accident',\n",
       " 'according',\n",
       " 'account',\n",
       " 'accurate',\n",
       " 'achieve',\n",
       " 'acting',\n",
       " 'active',\n",
       " 'activist',\n",
       " 'activity',\n",
       " 'actor',\n",
       " 'actual',\n",
       " 'ad',\n",
       " 'adam',\n",
       " 'adapt',\n",
       " 'add',\n",
       " 'added',\n",
       " 'addition',\n",
       " 'address',\n",
       " 'admit',\n",
       " 'adult',\n",
       " 'advance',\n",
       " 'advanced',\n",
       " 'advantage',\n",
       " 'advice',\n",
       " 'affect',\n",
       " 'affected',\n",
       " 'afford',\n",
       " 'afghanistan',\n",
       " 'afraid',\n",
       " 'africa',\n",
       " 'african',\n",
       " 'afternoon',\n",
       " 'agency',\n",
       " 'agent',\n",
       " 'aging',\n",
       " 'agree',\n",
       " 'agreed',\n",
       " 'agriculture',\n",
       " 'ah',\n",
       " 'ahead',\n",
       " 'aid',\n",
       " 'aim',\n",
       " 'airplane',\n",
       " 'airport',\n",
       " 'al',\n",
       " 'algorithm',\n",
       " 'alien',\n",
       " 'alive',\n",
       " 'allowed',\n",
       " 'allowing',\n",
       " 'allows',\n",
       " 'alternative',\n",
       " 'although',\n",
       " 'alzheimers',\n",
       " 'amazon',\n",
       " 'among',\n",
       " 'analysis',\n",
       " 'ancestor',\n",
       " 'ancient',\n",
       " 'anderson',\n",
       " 'angeles',\n",
       " 'anger',\n",
       " 'angle',\n",
       " 'angry',\n",
       " 'ant',\n",
       " 'antibiotic',\n",
       " 'anybody',\n",
       " 'anymore',\n",
       " 'anyway',\n",
       " 'anywhere',\n",
       " 'apart',\n",
       " 'apartment',\n",
       " 'app',\n",
       " 'apparently',\n",
       " 'appear',\n",
       " 'apple',\n",
       " 'application',\n",
       " 'applied',\n",
       " 'apply',\n",
       " 'appreciate',\n",
       " 'approach',\n",
       " 'appropriate',\n",
       " 'arab',\n",
       " 'architect',\n",
       " 'architecture',\n",
       " 'argue',\n",
       " 'argument',\n",
       " 'arm',\n",
       " 'army',\n",
       " 'arrived',\n",
       " 'article',\n",
       " 'artificial',\n",
       " 'artist',\n",
       " 'asia',\n",
       " 'aside',\n",
       " 'aspect',\n",
       " 'asset',\n",
       " 'associated',\n",
       " 'assume',\n",
       " 'assumption',\n",
       " 'asteroid',\n",
       " 'atmosphere',\n",
       " 'atom',\n",
       " 'attack',\n",
       " 'attempt',\n",
       " 'attitude',\n",
       " 'australia',\n",
       " 'author',\n",
       " 'authority',\n",
       " 'autism',\n",
       " 'automatically',\n",
       " 'available',\n",
       " 'avoid',\n",
       " 'aware',\n",
       " 'awareness',\n",
       " 'awesome',\n",
       " 'awful',\n",
       " 'baby',\n",
       " 'background',\n",
       " 'bacteria',\n",
       " 'bag',\n",
       " 'balance',\n",
       " 'ball',\n",
       " 'balloon',\n",
       " 'band',\n",
       " 'bang',\n",
       " 'bank',\n",
       " 'bar',\n",
       " 'barely',\n",
       " 'barrier',\n",
       " 'base',\n",
       " 'basic',\n",
       " 'basis',\n",
       " 'bat',\n",
       " 'battery',\n",
       " 'battle',\n",
       " 'beach',\n",
       " 'bear',\n",
       " 'beat',\n",
       " 'beauty',\n",
       " 'becoming',\n",
       " 'bed',\n",
       " 'bee',\n",
       " 'behave',\n",
       " 'behavior',\n",
       " 'belief',\n",
       " 'believed',\n",
       " 'benefit',\n",
       " 'bet',\n",
       " 'bias',\n",
       " 'bicycle',\n",
       " 'bigger',\n",
       " 'biggest',\n",
       " 'bike',\n",
       " 'bill',\n",
       " 'biological',\n",
       " 'biologist',\n",
       " 'biology',\n",
       " 'bird',\n",
       " 'birth',\n",
       " 'birthday',\n",
       " 'blind',\n",
       " 'block',\n",
       " 'blog',\n",
       " 'blood',\n",
       " 'blow',\n",
       " 'blue',\n",
       " 'board',\n",
       " 'boat',\n",
       " 'bomb',\n",
       " 'bond',\n",
       " 'bone',\n",
       " 'border',\n",
       " 'boring',\n",
       " 'boston',\n",
       " 'bottle',\n",
       " 'bottom',\n",
       " 'bought',\n",
       " 'boundary',\n",
       " 'box',\n",
       " 'boy',\n",
       " 'branch',\n",
       " 'brand',\n",
       " 'brazil',\n",
       " 'bread',\n",
       " 'breaking',\n",
       " 'breast',\n",
       " 'breath',\n",
       " 'breathe',\n",
       " 'breathing',\n",
       " 'bridge',\n",
       " 'bright',\n",
       " 'brilliant',\n",
       " 'bringing',\n",
       " 'brings',\n",
       " 'britain',\n",
       " 'british',\n",
       " 'broke',\n",
       " 'broken',\n",
       " 'brother',\n",
       " 'brown',\n",
       " 'bubble',\n",
       " 'budget',\n",
       " 'bunch',\n",
       " 'burn',\n",
       " 'burning',\n",
       " 'bus',\n",
       " 'bush',\n",
       " 'busy',\n",
       " 'button',\n",
       " 'buying',\n",
       " 'california',\n",
       " 'calling',\n",
       " 'camera',\n",
       " 'camp',\n",
       " 'campaign',\n",
       " 'canada',\n",
       " 'cancer',\n",
       " 'candidate',\n",
       " 'capability',\n",
       " 'capable',\n",
       " 'capacity',\n",
       " 'capital',\n",
       " 'capitalism',\n",
       " 'capture',\n",
       " 'carbon',\n",
       " 'card',\n",
       " 'career',\n",
       " 'careful',\n",
       " 'carefully',\n",
       " 'carried',\n",
       " 'carry',\n",
       " 'carrying',\n",
       " 'cartoon',\n",
       " 'cat',\n",
       " 'catch',\n",
       " 'category',\n",
       " 'caught',\n",
       " 'caused',\n",
       " 'causing',\n",
       " 'cave',\n",
       " 'celebrate',\n",
       " 'cent',\n",
       " 'central',\n",
       " 'ceo',\n",
       " 'certainly',\n",
       " 'chain',\n",
       " 'chair',\n",
       " 'challenging',\n",
       " 'channel',\n",
       " 'chapter',\n",
       " 'character',\n",
       " 'characteristic',\n",
       " 'charge',\n",
       " 'charity',\n",
       " 'charles',\n",
       " 'chart',\n",
       " 'cheap',\n",
       " 'cheaper',\n",
       " 'check',\n",
       " 'chemical',\n",
       " 'chemistry',\n",
       " 'chest',\n",
       " 'chicago',\n",
       " 'chicken',\n",
       " 'childhood',\n",
       " 'childrens',\n",
       " 'chimpanzee',\n",
       " 'china',\n",
       " 'chinese',\n",
       " 'chip',\n",
       " 'choose',\n",
       " 'chose',\n",
       " 'chris',\n",
       " 'christian',\n",
       " 'christmas',\n",
       " 'church',\n",
       " 'circle',\n",
       " 'circuit',\n",
       " 'circumstance',\n",
       " 'citizen',\n",
       " 'civil',\n",
       " 'civilization',\n",
       " 'claim',\n",
       " 'class',\n",
       " 'classic',\n",
       " 'classroom',\n",
       " 'clean',\n",
       " 'clearly',\n",
       " 'clever',\n",
       " 'click',\n",
       " 'client',\n",
       " 'climate',\n",
       " 'climb',\n",
       " 'clinic',\n",
       " 'clinical',\n",
       " 'clip',\n",
       " 'clock',\n",
       " 'closed',\n",
       " 'closely',\n",
       " 'closer',\n",
       " 'clothes',\n",
       " 'cloud',\n",
       " 'club',\n",
       " 'co',\n",
       " 'coal',\n",
       " 'coast',\n",
       " 'code',\n",
       " 'coffee',\n",
       " 'cognitive',\n",
       " 'cold',\n",
       " 'collaboration',\n",
       " 'collapse',\n",
       " 'colleague',\n",
       " 'collect',\n",
       " 'collected',\n",
       " 'collecting',\n",
       " 'collection',\n",
       " 'collective',\n",
       " 'college',\n",
       " 'colony',\n",
       " 'column',\n",
       " 'combination',\n",
       " 'combine',\n",
       " 'combined',\n",
       " 'comfort',\n",
       " 'comfortable',\n",
       " 'comment',\n",
       " 'commercial',\n",
       " 'commitment',\n",
       " 'committed',\n",
       " 'communicate',\n",
       " 'communication',\n",
       " 'compare',\n",
       " 'compared',\n",
       " 'compassion',\n",
       " 'competition',\n",
       " 'complete',\n",
       " 'complexity',\n",
       " 'complicated',\n",
       " 'component',\n",
       " 'computing',\n",
       " 'concept',\n",
       " 'concern',\n",
       " 'concerned',\n",
       " 'conclusion',\n",
       " 'concrete',\n",
       " 'conference',\n",
       " 'confidence',\n",
       " 'conflict',\n",
       " 'congress',\n",
       " 'connect',\n",
       " 'connected',\n",
       " 'connecting',\n",
       " 'connection',\n",
       " 'conscious',\n",
       " 'consciousness',\n",
       " 'consequence',\n",
       " 'conservation',\n",
       " 'conservative',\n",
       " 'consider',\n",
       " 'considered',\n",
       " 'constant',\n",
       " 'constantly',\n",
       " 'construction',\n",
       " 'consumer',\n",
       " 'consumption',\n",
       " 'contact',\n",
       " 'content',\n",
       " 'context',\n",
       " 'continent',\n",
       " 'continue',\n",
       " 'contract',\n",
       " 'contrast',\n",
       " 'contribute',\n",
       " 'controlled',\n",
       " 'conventional',\n",
       " 'conversation',\n",
       " 'convince',\n",
       " 'convinced',\n",
       " 'cook',\n",
       " 'cooking',\n",
       " 'cool',\n",
       " 'copy',\n",
       " 'coral',\n",
       " 'cord',\n",
       " 'core',\n",
       " 'corner',\n",
       " 'corporate',\n",
       " 'corporation',\n",
       " 'correct',\n",
       " 'corruption',\n",
       " 'cortex',\n",
       " 'count',\n",
       " 'courage',\n",
       " 'court',\n",
       " 'cover',\n",
       " 'covered',\n",
       " 'cow',\n",
       " 'crack',\n",
       " 'crash',\n",
       " 'crazy',\n",
       " 'creates',\n",
       " 'creation',\n",
       " 'creative',\n",
       " 'creativity',\n",
       " 'creature',\n",
       " 'credit',\n",
       " 'crime',\n",
       " 'criminal',\n",
       " 'crisis',\n",
       " 'critical',\n",
       " 'crop',\n",
       " 'cross',\n",
       " 'crowd',\n",
       " 'cry',\n",
       " 'cultural',\n",
       " 'cup',\n",
       " 'cure',\n",
       " 'curiosity',\n",
       " 'curious',\n",
       " 'current',\n",
       " 'currently',\n",
       " 'curve',\n",
       " 'customer',\n",
       " 'cutting',\n",
       " 'cycle',\n",
       " 'dad',\n",
       " 'daily',\n",
       " 'damage',\n",
       " 'dance',\n",
       " 'dancing',\n",
       " 'danger',\n",
       " 'dangerous',\n",
       " 'dark',\n",
       " 'darwin',\n",
       " 'database',\n",
       " 'date',\n",
       " 'daughter',\n",
       " 'david',\n",
       " 'de',\n",
       " 'dead',\n",
       " 'dealing',\n",
       " 'debate',\n",
       " 'debt',\n",
       " 'decide',\n",
       " 'decline',\n",
       " 'deep',\n",
       " 'deeper',\n",
       " 'deeply',\n",
       " 'defense',\n",
       " 'define',\n",
       " 'defined',\n",
       " 'definitely',\n",
       " 'definition',\n",
       " 'degree',\n",
       " 'deliver',\n",
       " 'demand',\n",
       " 'democracy',\n",
       " 'democratic',\n",
       " 'department',\n",
       " 'depending',\n",
       " 'depends',\n",
       " 'depression',\n",
       " 'depth',\n",
       " 'describe',\n",
       " 'described',\n",
       " 'desert',\n",
       " 'designed',\n",
       " 'designer',\n",
       " 'designing',\n",
       " 'desire',\n",
       " 'desk',\n",
       " 'despite',\n",
       " 'destroyed',\n",
       " 'destruction',\n",
       " 'detail',\n",
       " 'detect',\n",
       " 'determine',\n",
       " 'develop',\n",
       " 'developing',\n",
       " 'development',\n",
       " 'device',\n",
       " 'dictionary',\n",
       " 'died',\n",
       " 'diet',\n",
       " 'differently',\n",
       " 'difficulty',\n",
       " 'digital',\n",
       " 'dignity',\n",
       " 'dimension',\n",
       " 'dinner',\n",
       " 'dinosaur',\n",
       " 'dioxide',\n",
       " 'direct',\n",
       " 'direction',\n",
       " 'directly',\n",
       " 'director',\n",
       " 'disability',\n",
       " 'disaster',\n",
       " 'discover',\n",
       " 'discovery',\n",
       " 'discussion',\n",
       " 'dish',\n",
       " 'disorder',\n",
       " 'display',\n",
       " 'distance',\n",
       " 'distributed',\n",
       " 'distribution',\n",
       " 'diversity',\n",
       " 'divide',\n",
       " 'dna',\n",
       " 'doctor',\n",
       " 'document',\n",
       " 'dog',\n",
       " 'dolphin',\n",
       " 'domestic',\n",
       " 'door',\n",
       " 'dot',\n",
       " 'double',\n",
       " 'doubt',\n",
       " 'dozen',\n",
       " 'dr',\n",
       " 'dramatic',\n",
       " 'dramatically',\n",
       " 'draw',\n",
       " 'drawing',\n",
       " 'drink',\n",
       " 'drinking',\n",
       " 'driven',\n",
       " 'driver',\n",
       " 'driving',\n",
       " 'drone',\n",
       " 'drop',\n",
       " 'dropped',\n",
       " 'drug',\n",
       " 'dry',\n",
       " 'due',\n",
       " 'dust',\n",
       " 'dying',\n",
       " 'dynamic',\n",
       " 'ear',\n",
       " 'earlier',\n",
       " 'easier',\n",
       " 'easily',\n",
       " 'east',\n",
       " 'eastern',\n",
       " 'eat',\n",
       " 'eating',\n",
       " 'economic',\n",
       " 'economics',\n",
       " 'economist',\n",
       " 'economy',\n",
       " 'ecosystem',\n",
       " 'edge',\n",
       " 'educational',\n",
       " 'effective',\n",
       " 'effectively',\n",
       " 'efficiency',\n",
       " 'efficient',\n",
       " 'effort',\n",
       " 'egg',\n",
       " 'egypt',\n",
       " 'einstein',\n",
       " 'el',\n",
       " 'election',\n",
       " 'electric',\n",
       " 'electrical',\n",
       " 'electricity',\n",
       " 'electronic',\n",
       " 'element',\n",
       " 'elephant',\n",
       " 'elite',\n",
       " 'email',\n",
       " 'embrace',\n",
       " 'emergency',\n",
       " 'emerging',\n",
       " 'emission',\n",
       " 'emotion',\n",
       " 'emotional',\n",
       " 'empathy',\n",
       " 'employee',\n",
       " 'empty',\n",
       " 'enable',\n",
       " 'encounter',\n",
       " 'encourage',\n",
       " 'ended',\n",
       " 'enemy',\n",
       " 'engage',\n",
       " 'engaged',\n",
       " 'engaging',\n",
       " 'engine',\n",
       " 'engineer',\n",
       " 'engineering',\n",
       " 'england',\n",
       " 'english',\n",
       " 'enjoy',\n",
       " 'enormous',\n",
       " 'enter',\n",
       " 'entertainment',\n",
       " 'entirely',\n",
       " 'entrepreneur',\n",
       " 'environmental',\n",
       " 'epidemic',\n",
       " 'equal',\n",
       " 'equality',\n",
       " 'equally',\n",
       " 'equation',\n",
       " 'equipment',\n",
       " 'equivalent',\n",
       " 'era',\n",
       " 'error',\n",
       " 'escape',\n",
       " 'essential',\n",
       " 'essentially',\n",
       " 'estimate',\n",
       " 'etc',\n",
       " 'europe',\n",
       " 'european',\n",
       " 'evening',\n",
       " 'event',\n",
       " 'everyday',\n",
       " 'everywhere',\n",
       " 'evidence',\n",
       " 'evil',\n",
       " 'evolution',\n",
       " 'evolutionary',\n",
       " 'evolve',\n",
       " 'evolved',\n",
       " 'exact',\n",
       " 'except',\n",
       " 'exception',\n",
       " 'exchange',\n",
       " 'excited',\n",
       " 'exciting',\n",
       " 'excuse',\n",
       " 'exercise',\n",
       " 'exist',\n",
       " 'existed',\n",
       " 'existence',\n",
       " 'existing',\n",
       " 'exists',\n",
       " 'expand',\n",
       " 'expect',\n",
       " 'expectation',\n",
       " 'expected',\n",
       " 'expensive',\n",
       " 'experienced',\n",
       " 'experiment',\n",
       " 'expert',\n",
       " 'explain',\n",
       " 'explained',\n",
       " 'explanation',\n",
       " 'exploration',\n",
       " 'explore',\n",
       " 'exposed',\n",
       " 'express',\n",
       " 'expression',\n",
       " 'extent',\n",
       " 'extra',\n",
       " 'extraordinary',\n",
       " 'extreme',\n",
       " 'extremely',\n",
       " 'facebook',\n",
       " 'faced',\n",
       " 'facility',\n",
       " 'facing',\n",
       " 'factor',\n",
       " 'factory',\n",
       " 'fail',\n",
       " 'failed',\n",
       " 'failure',\n",
       " 'fair',\n",
       " 'fairly',\n",
       " 'faith',\n",
       " 'fake',\n",
       " 'falling',\n",
       " 'false',\n",
       " 'familiar',\n",
       " 'famous',\n",
       " 'fan',\n",
       " 'fantastic',\n",
       " 'farm',\n",
       " 'farmer',\n",
       " 'fascinating',\n",
       " 'fashion',\n",
       " 'faster',\n",
       " 'fat',\n",
       " 'favorite',\n",
       " 'feature',\n",
       " 'federal',\n",
       " 'feed',\n",
       " 'feedback',\n",
       " 'feeding',\n",
       " 'fell',\n",
       " 'fellow',\n",
       " 'female',\n",
       " 'fewer',\n",
       " 'fiber',\n",
       " 'fiction',\n",
       " 'fight',\n",
       " 'fighting',\n",
       " 'figured',\n",
       " 'file',\n",
       " 'fill',\n",
       " 'filled',\n",
       " 'film',\n",
       " 'filter',\n",
       " 'final',\n",
       " 'finance',\n",
       " 'financial',\n",
       " 'finding',\n",
       " 'fine',\n",
       " 'finger',\n",
       " 'finish',\n",
       " 'finished',\n",
       " 'fire',\n",
       " 'firm',\n",
       " 'fish',\n",
       " 'fishing',\n",
       " 'fit',\n",
       " 'fix',\n",
       " 'fixed',\n",
       " 'flag',\n",
       " 'flat',\n",
       " 'flew',\n",
       " 'flight',\n",
       " 'floating',\n",
       " 'floor',\n",
       " 'flow',\n",
       " 'flower',\n",
       " 'flu',\n",
       " 'fly',\n",
       " 'flying',\n",
       " 'focused',\n",
       " 'fold',\n",
       " 'folk',\n",
       " 'follow',\n",
       " 'followed',\n",
       " 'following',\n",
       " 'forced',\n",
       " 'foreign',\n",
       " 'forest',\n",
       " 'forever',\n",
       " 'forget',\n",
       " 'formed',\n",
       " 'former',\n",
       " 'forth',\n",
       " 'fossil',\n",
       " 'foundation',\n",
       " 'fourth',\n",
       " 'frame',\n",
       " 'framework',\n",
       " 'france',\n",
       " 'francisco',\n",
       " 'frankly',\n",
       " 'freedom',\n",
       " 'french',\n",
       " 'frequency',\n",
       " 'fresh',\n",
       " 'fruit',\n",
       " 'fuel',\n",
       " 'fully',\n",
       " 'fun',\n",
       " 'function',\n",
       " 'fund',\n",
       " 'fundamental',\n",
       " 'fundamentally',\n",
       " 'funding',\n",
       " 'funny',\n",
       " 'gain',\n",
       " 'galaxy',\n",
       " 'gang',\n",
       " 'gap',\n",
       " 'garden',\n",
       " 'gas',\n",
       " 'gate',\n",
       " 'gather',\n",
       " 'gay',\n",
       " 'gdp',\n",
       " 'gender',\n",
       " 'gene',\n",
       " 'general',\n",
       " 'generally',\n",
       " 'generate',\n",
       " 'genetic',\n",
       " 'genius',\n",
       " 'genome',\n",
       " 'gentleman',\n",
       " 'george',\n",
       " 'german',\n",
       " 'germany',\n",
       " 'giant',\n",
       " 'gift',\n",
       " 'glass',\n",
       " 'globe',\n",
       " 'goal',\n",
       " 'gold',\n",
       " 'google',\n",
       " 'gotten',\n",
       " 'gps',\n",
       " 'grab',\n",
       " 'grade',\n",
       " 'graduate',\n",
       " 'grain',\n",
       " 'grand',\n",
       " 'grandfather',\n",
       " 'grandmother',\n",
       " 'graph',\n",
       " 'graphic',\n",
       " 'gravity',\n",
       " 'gray',\n",
       " 'greater',\n",
       " 'greatest',\n",
       " 'greek',\n",
       " 'green',\n",
       " 'greenhouse',\n",
       " 'grew',\n",
       " 'grid',\n",
       " 'grown',\n",
       " 'grows',\n",
       " 'growth',\n",
       " 'guard',\n",
       " 'guide',\n",
       " 'gun',\n",
       " 'gut',\n",
       " 'habit',\n",
       " 'habitat',\n",
       " 'hair',\n",
       " 'hall',\n",
       " 'handle',\n",
       " 'hang',\n",
       " 'happiness',\n",
       " 'harder',\n",
       " 'harm',\n",
       " 'harvard',\n",
       " 'hate',\n",
       " 'healthcare',\n",
       " 'healthy',\n",
       " 'hearing',\n",
       " 'heat',\n",
       " 'heavy',\n",
       " 'hed',\n",
       " 'height',\n",
       " 'held',\n",
       " 'hell',\n",
       " 'helped',\n",
       " 'helping',\n",
       " 'hero',\n",
       " 'hey',\n",
       " 'hidden',\n",
       " 'hide',\n",
       " 'higher',\n",
       " 'highest',\n",
       " 'highly',\n",
       " 'highway',\n",
       " 'hill',\n",
       " 'hiv',\n",
       " 'holding',\n",
       " 'hole',\n",
       " 'honest',\n",
       " 'honor',\n",
       " 'hopefully',\n",
       " 'hoping',\n",
       " 'hormone',\n",
       " 'horrible',\n",
       " 'horse',\n",
       " 'hospital',\n",
       " 'host',\n",
       " 'hot',\n",
       " 'hotel',\n",
       " 'housing',\n",
       " 'however',\n",
       " 'humanity',\n",
       " 'hurt',\n",
       " 'husband',\n",
       " 'hydrogen',\n",
       " 'ice',\n",
       " 'ideal',\n",
       " 'identify',\n",
       " 'identity',\n",
       " 'ignore',\n",
       " 'ii',\n",
       " 'illegal',\n",
       " 'illness',\n",
       " 'illusion',\n",
       " 'imagination',\n",
       " 'imagined',\n",
       " 'immediately',\n",
       " 'immune',\n",
       " 'implication',\n",
       " 'importance',\n",
       " 'importantly',\n",
       " 'impossible',\n",
       " 'improve',\n",
       " 'improvement',\n",
       " 'incentive',\n",
       " 'inch',\n",
       " 'include',\n",
       " 'including',\n",
       " 'income',\n",
       " 'increase',\n",
       " 'increased',\n",
       " 'increasing',\n",
       " 'increasingly',\n",
       " 'incredibly',\n",
       " 'indeed',\n",
       " 'independent',\n",
       " 'india',\n",
       " 'indian',\n",
       " 'industrial',\n",
       " 'industry',\n",
       " 'inequality',\n",
       " 'infected',\n",
       " 'infection',\n",
       " 'influence',\n",
       " 'infrastructure',\n",
       " 'ingredient',\n",
       " 'injury',\n",
       " 'inner',\n",
       " 'innovation',\n",
       " 'innovative',\n",
       " 'input',\n",
       " 'insect',\n",
       " 'insight',\n",
       " 'inspiration',\n",
       " 'inspired',\n",
       " 'instance',\n",
       " 'institute',\n",
       " 'institution',\n",
       " 'instruction',\n",
       " 'instrument',\n",
       " 'insurance',\n",
       " 'intellectual',\n",
       " 'intelligence',\n",
       " 'intelligent',\n",
       " 'intense',\n",
       " 'interact',\n",
       " 'interaction',\n",
       " 'interest',\n",
       " 'interface',\n",
       " 'internal',\n",
       " 'international',\n",
       " 'intervention',\n",
       " 'interview',\n",
       " 'introduce',\n",
       " 'introduced',\n",
       " 'invent',\n",
       " 'invented',\n",
       " 'invention',\n",
       " 'invest',\n",
       " 'investment',\n",
       " 'invisible',\n",
       " 'invite',\n",
       " 'invited',\n",
       " 'involved',\n",
       " 'iphone',\n",
       " 'iran',\n",
       " 'iraq',\n",
       " 'island',\n",
       " 'israel',\n",
       " 'item',\n",
       " 'itll',\n",
       " 'jail',\n",
       " 'james',\n",
       " 'japan',\n",
       " 'japanese',\n",
       " 'john',\n",
       " 'join',\n",
       " 'joined',\n",
       " 'joke',\n",
       " 'journal',\n",
       " 'journalist',\n",
       " 'journey',\n",
       " 'joy',\n",
       " 'judge',\n",
       " 'judgment',\n",
       " 'jump',\n",
       " 'justice',\n",
       " 'keeping',\n",
       " 'kenya',\n",
       " 'kept',\n",
       " 'kill',\n",
       " 'killed',\n",
       " 'killing',\n",
       " 'kilometer',\n",
       " 'king',\n",
       " 'kingdom',\n",
       " 'kitchen',\n",
       " 'knee',\n",
       " 'knowing',\n",
       " 'knowledge',\n",
       " 'korea',\n",
       " 'la',\n",
       " 'lab',\n",
       " ...]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2467"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-100-69e35ba8d15b>, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-100-69e35ba8d15b>\"\u001b[0;36m, line \u001b[0;32m7\u001b[0m\n\u001b[0;31m    model.wv.__getitem__('climate')\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "# a function that turns a document (in vectorized format) into the vectors of its words\n",
    "def doc2words(document_sparse, feature_names, word2vec_model):\n",
    "    X = document_sparse.toarray()\n",
    "    features = vectorizer.get_feature_names\n",
    "    for i in range(len(X)):\n",
    "        \n",
    "    model.wv.__getitem__('climate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "document_sparse = tf # tf or tfidf\n",
    "word2vec_model = model_TED # model_TED or model_google_100 etc.\n",
    "feature_names = tf_vectorizer.get_feature_names()\n",
    "# doc2words(document_sparse, feature_names, word2vec_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doc_vec = tf.todense()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 50)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_vec = model.wv.__getitem__(feature_names)\n",
    "feature_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_vec = doc_vec.dot(feature_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 50)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ -17.39162118,  -75.65193581,   63.26797668,   81.26093022,\n",
       "          -14.32507966, -166.41762158,  -52.56966448, -239.29081626,\n",
       "           91.46040914,  -66.4453373 ,  -80.00524382,   46.70433163,\n",
       "           82.05821881,   -3.50390634,  -13.78361464,  180.81476691,\n",
       "           25.97947541,    6.34493195,  157.68742285,   59.36388117,\n",
       "          -45.33857208,  112.53168071,  -40.97641475,   13.97636647,\n",
       "           90.35267034,  -13.9588852 ,   86.00223244,  -24.00281094,\n",
       "           90.28083895,   15.90018967,  -63.94696609,   42.33036307,\n",
       "          -32.48594836,    6.64506606,   19.80055169,  -75.42120159,\n",
       "          -79.27954104,  -80.04876735,  -79.94421258,   42.64000593,\n",
       "          116.24749941,  -29.15994209,   27.51159701,  -47.38383486,\n",
       "           81.54624244,  -28.61150743,   -2.49436879,   -9.64589779,\n",
       "           81.32097096,  -31.64717222]])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N = 1000\n",
    "\n",
    "document_sparse = tfidf\n",
    "word2vec_model = model_TED # model_TED or model_google_100 etc.\n",
    "feature_names = tf_vectorizer.get_feature_names()\n",
    "\n",
    "doc_vec = tf.todense()[N]\n",
    "feature_vec = word2vec_model.wv.__getitem__(feature_names)\n",
    "\n",
    "\n",
    "\n",
    "np.savetxt('./data/lsa_data.tsv', X, delimiter='\\t',newline='\\n')\n",
    "\n",
    "Xlabel = list(df_all.title)\n",
    "with open('./data/lsa_meta.tsv', 'w') as file:\n",
    "    for label in Xlabel:\n",
    "        file.write(label+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 1024)\t0.07741893711812595\n",
      "  (0, 1802)\t0.04418942619454977\n",
      "  (0, 352)\t0.07598581169337414\n",
      "  (0, 1475)\t0.04471890751802793\n",
      "  (0, 665)\t0.14569010010696387\n",
      "  (0, 628)\t0.06805210986559387\n",
      "  (0, 410)\t0.20827308839668318\n",
      "  (0, 1366)\t0.09112643658288003\n",
      "  (0, 1905)\t0.04179295610060574\n",
      "  (0, 1439)\t0.036596253619872995\n",
      "  (0, 944)\t0.13073235562824667\n",
      "  (0, 496)\t0.07929216052914853\n",
      "  (0, 1273)\t0.07094541468937776\n",
      "  (0, 760)\t0.136110057595616\n",
      "  (0, 1705)\t0.03604121251267758\n",
      "  (0, 169)\t0.03481904146544406\n",
      "  (0, 452)\t0.03176483861689968\n",
      "  (0, 1476)\t0.04118345584770355\n",
      "  (0, 1106)\t0.06586559769276992\n",
      "  (0, 478)\t0.03587581807373999\n",
      "  (0, 41)\t0.045563218291440014\n",
      "  (0, 226)\t0.2310001089933845\n",
      "  (0, 925)\t0.03612483431716769\n",
      "  (0, 270)\t0.04079479481235949\n",
      "  (0, 1768)\t0.13727942104348764\n",
      "  :\t:\n",
      "  (0, 1937)\t0.04023596750144571\n",
      "  (0, 1614)\t0.0390311730414011\n",
      "  (0, 1930)\t0.03591693837602586\n",
      "  (0, 1627)\t0.03299610562380522\n",
      "  (0, 1771)\t0.04770404376566258\n",
      "  (0, 1144)\t0.03277607923159967\n",
      "  (0, 232)\t0.03547270734468888\n",
      "  (0, 1501)\t0.039646080264574265\n",
      "  (0, 1727)\t0.03409586992374188\n",
      "  (0, 1168)\t0.049770620907716036\n",
      "  (0, 1801)\t0.045661081531818186\n",
      "  (0, 1389)\t0.039878322148884475\n",
      "  (0, 1330)\t0.046266919333372895\n",
      "  (0, 1113)\t0.049629672259359485\n",
      "  (0, 49)\t0.0467980742092099\n",
      "  (0, 1678)\t0.04079479481235949\n",
      "  (0, 1586)\t0.04312144991535858\n",
      "  (0, 771)\t0.03523762313217872\n",
      "  (0, 1376)\t0.03555217767636484\n",
      "  (0, 1429)\t0.04011547956851235\n",
      "  (0, 928)\t0.048561695980168296\n",
      "  (0, 891)\t0.0394185542789255\n",
      "  (0, 233)\t0.04518009482467808\n",
      "  (0, 1550)\t0.04668980989068088\n",
      "  (0, 1774)\t0.037366211324735936\n"
     ]
    }
   ],
   "source": [
    "print(tfidf[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
